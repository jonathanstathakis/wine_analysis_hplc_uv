{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-10-30\n",
    "\n",
    "Continuing from here: [creating_3d_dataset](/Users/jonathan/mres_thesis/wine_analysis_hplc_uv/src/wine_analysis_hplc_uv/notebooks/creating_3d_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document will contain my PCA analysis of a sample HPLC-DAD dataset for insights, including rank estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from eda_by_category_methods import DTWProcessing\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import signal\n",
    "import seaborn.objects as so\n",
    "import seaborn as sns\n",
    "from pybaselines import Baseline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "process = DTWProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wine_analysis_hplc_uv.notebooks.xgboost_modeling.dataextract import (\n",
    "    RawTestSet3DCreator,\n",
    ")\n",
    "from wine_analysis_hplc_uv import definitions\n",
    "\n",
    "rtsc = RawTestSet3DCreator(definitions.DB_PATH)\n",
    "\n",
    "dset = rtsc.df\n",
    "dset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d111 = (\n",
    "    dset.loc[lambda df: df.code_wine.str.contains(\"111\")]\n",
    "    .drop([\"detection\", \"code_wine\", \"color\", \"varietal\", \"id\", \"mins\"], axis=1)\n",
    "    .reset_index(drop=True)\n",
    "    .rename_axis(\"i\")\n",
    ")\n",
    "\n",
    "d111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data needs to be baseline corrected and smoothed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt\n",
    "m_d111 = d111.melt(\n",
    "    var_name=\"wavelength\", value_name=\"abs\", ignore_index=False\n",
    ").reset_index()\n",
    "m_d111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display head of melted frame\n",
    "m_d111.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot raw\n",
    "fig, ax = plt.subplots(figsize=(5, 3), dpi=150)\n",
    "\n",
    "p = m_d111.pipe(\n",
    "    lambda x: sns.lineplot(\n",
    "        data=x, hue=\"wavelength\", x=\"i\", y=\"abs\", legend=False, ax=ax\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth\n",
    "\n",
    "\n",
    "def smooth(\n",
    "    df,\n",
    "    grouper: str,\n",
    "    col: str,\n",
    "    smoothed_colname: str,\n",
    "    savgol_kws: dict = dict(window_length=5, polyorder=2),\n",
    "):\n",
    "    \"\"\"\n",
    "    Smooth the signal with savgol filter.\n",
    "\n",
    "    args:\n",
    "\n",
    "    df: long format dataframe with a group label column\n",
    "    grouper: column containing the labels of the groups to iterate over\n",
    "    smoothed_colname: name of the output column\n",
    "    savgol_kws: refer to scipy.signal.savgol_filter\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.assign(\n",
    "        **{\n",
    "            smoothed_colname: lambda df: df.groupby(grouper)[col].transform(\n",
    "                lambda x: pd.Series(savgol_filter(x, **savgol_kws), index=x.index)\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    display(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "m_d111 = smooth(\n",
    "    m_d111, \"wavelength\", \"abs\", \"smooth\", savgol_kws=dict(window_length=4, polyorder=2)\n",
    ")\n",
    "m_d111.groupby(\"wavelength\").get_group(\"nm_256\").pipe(\n",
    "    lambda x: so.Plot(data=x, x=\"i\", y=\"smooth\").add(so.Line())\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcorr\n",
    "\n",
    "\n",
    "def baseline_subtract(df, col, grouper, baseline_corrected_name: str):\n",
    "    \"\"\"\n",
    "    Baseline subtract\n",
    "\n",
    "    args:\n",
    "\n",
    "    df - long df with wavelengths as an id col.\n",
    "    col - target column to be transformed\n",
    "    grouper - column containing the group labels, i.e. wavelengths\n",
    "    baseline_corrected_name - the name of the newly created column\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.assign(\n",
    "        **dict(\n",
    "            bline=lambda df: df.groupby(grouper).smooth.transform(\n",
    "                lambda x: pd.Series(\n",
    "                    Baseline(x.index).asls(\n",
    "                        x,\n",
    "                        max_iter=50,\n",
    "                        tol=1e-3,\n",
    "                        lam=1e6,\n",
    "                    )[0],\n",
    "                    index=x.index,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ).assign(**{baseline_corrected_name: lambda df: df.eval(\"smooth-bline\")})\n",
    "    return df\n",
    "\n",
    "\n",
    "m_d111 = baseline_subtract(m_d111, \"smooth\", \"wavelength\", \"bcorr\")\n",
    "\n",
    "display(m_d111.head())\n",
    "\n",
    "# plot overlay of baseline and original signal\n",
    "(\n",
    "    m_d111.groupby(\"wavelength\")\n",
    "    .get_group(\"nm_256\")\n",
    "    .loc[:, [\"i\", \"smooth\", \"bline\"]]\n",
    "    .pipe(lambda df: df if display(df) else df)  # display df\n",
    "    .melt(var_name=\"signal\", value_name=\"abs\", id_vars=\"i\")\n",
    "    .pipe(lambda df: df if display(df) else df)  # display df\n",
    "    .pipe(lambda df: so.Plot(data=df, x=\"i\", y=\"abs\", color=\"signal\").add(so.Line()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data needs to be scaled and centered. Also, subset to the region of interest, < 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to <4000\n",
    "\n",
    "m_d111_subset = m_d111.loc[m_d111.i < 4000]\n",
    "\n",
    "display(m_d111_subset.head())\n",
    "\n",
    "(\n",
    "    m_d111_subset.groupby(\"wavelength\")\n",
    "    .get_group(\"nm_256\")\n",
    "    .reset_index()\n",
    "    .pipe(lambda x: so.Plot(data=x, x=\"i\", y=\"bcorr\").add(so.Line()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_center(df, col: str):\n",
    "    # scale and center\n",
    "\n",
    "    df = df.assign(\n",
    "        scale_center=lambda df: scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    )\n",
    "    display(df.head())\n",
    "    df.info()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "m_d111_subset = scale_and_center(m_d111_subset, \"bcorr\")\n",
    "\n",
    "m_d111_subset.groupby(\"wavelength\").get_group(\"nm_256\").pipe(\n",
    "    lambda x: so.Plot(data=x, x=\"i\", y=\"scale_center\").add(so.Line()).show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "@juan_mcriter_2020 says that PCA can be used to estimate the number of compounds in $X$. @nardecchia_2020 says that this is based on \"the scree test for the number of factors\". Plotting eigenvalues against components, the chemical rank is defined as the point at which the curve elbows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component selection is necessarily arbitrary, ergo I will define the threshold of variance % as greater than 1E-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_components(df):\n",
    "    \"\"\"\n",
    "    Calculate the number of principal components in the dataset defined as the set of those containing greater than 0.0001 variance ratio.\n",
    "\n",
    "    args\n",
    "\n",
    "    df: an augmented dataframe with more rows than columns, i.e. observations x wavelengths\n",
    "    \"\"\"\n",
    "\n",
    "    # initialise the PCA object and then fit transform on df\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(df)\n",
    "\n",
    "    # construct a DataFrame of two columns: n = the number of components; and var_ratio = the variance ratio explained by that component\n",
    "\n",
    "    screeplot_data = pd.DataFrame(\n",
    "        dict(\n",
    "            n=np.arange(pca.n_components_) + 1, var_ratio=pca.explained_variance_ratio_\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # filter out components with less than 1E-3 variance ratio\n",
    "    selected_components = screeplot_data.loc[lambda x: x.var_ratio > 1e-3]\n",
    "\n",
    "    # display the selected components table\n",
    "    display(selected_components)\n",
    "\n",
    "    # create the scree plot, marking the last retained component\n",
    "    screeplot_data.pipe(\n",
    "        lambda x: so.Plot(data=x.loc[0:20], x=\"n\", y=\"var_ratio\")\n",
    "        .add(so.Line())\n",
    "        .add(\n",
    "            so.Dot(marker=\"x\"),\n",
    "            data=selected_components.iloc[[-1]],\n",
    "            x=\"n\",\n",
    "            y=\"var_ratio\",\n",
    "        )\n",
    "    ).show()\n",
    "    display()\n",
    "\n",
    "    # number of components is equal to the number of rows of the selected_components table\n",
    "\n",
    "    n_components = selected_components.shape[0]\n",
    "\n",
    "    # display the nmber of components\n",
    "    display(f\"n components = {n_components}\")\n",
    "\n",
    "    return n_components\n",
    "\n",
    "\n",
    "n_components = calculate_components(\n",
    "    m_d111_subset.pivot_table(columns=\"wavelength\", values=\"scale_center\", index=\"i\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore for this dataset, the chemical rank is 6. This is very surprising, as I was expecting at least as many components as peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the peaks defined as those as prominant as 2% of the maxima of the signal\n",
    "\n",
    "\n",
    "m_d111_subset = m_d111_subset.assign(\n",
    "    peaks=lambda df: df.groupby(\"wavelength\")[\"bcorr\"].transform(\n",
    "        lambda x: x.iloc[signal.find_peaks(x, prominence=x.max() * 0.02)[0]]\n",
    "    )\n",
    ")\n",
    "\n",
    "display(m_d111_subset.head())\n",
    "\n",
    "m_d111_subset.groupby(\"wavelength\").get_group(\"nm_256\").pipe(\n",
    "    lambda df: so.Plot(df, x=\"i\").add(so.Line(), y=\"bcorr\").add(so.Dot(), y=\"peaks\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a prominence value of 2 is appropriate for 256nm, but is it appropriate for all wavelengths?\n",
    "\n",
    "(\n",
    "    m_d111_subset.loc[\n",
    "        lambda df: df.wavelength.isin([\"nm_190\", \"nm_256\", \"nm_400\"])\n",
    "    ].pipe(\n",
    "        lambda df: so.Plot(df, x=\"i\")\n",
    "        .facet(\"wavelength\")\n",
    "        .share(y=False)\n",
    "        .add(so.Line(), y=\"bcorr\")\n",
    "        .add(so.Dot(), y=\"peaks\")\n",
    "        .layout(size=(15, 3))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d111_subset.groupby(\"wavelength\").get_group(\"nm_190\").pipe(\n",
    "    lambda df: so.Plot(df, x=\"i\").add(so.Line(), y=\"bcorr\").add(so.Dot(), y=\"peaks\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d111_subset.groupby(\"wavelength\")[\"peaks\"].agg(lambda x: x.dropna().shape[0]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, there is a disconnect between the expected components and the number of peaks. Ah well, pushing on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLISMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLe-to-use Interactive Self-modeling Mixture Analysis.\n",
    "\n",
    "Selection of pure variables from $D$.\n",
    "\n",
    "First published by @windig_1991."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d111_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Algorithm\n",
    "def simplisma(d, nr, error):\n",
    "    def wmat(c, imp, irank, jvar):\n",
    "        dm = np.zeros((irank + 1, irank + 1))\n",
    "        dm[0, 0] = c[jvar, jvar]\n",
    "\n",
    "        for k in range(irank):\n",
    "            kvar = int(imp[k])\n",
    "\n",
    "            dm[0, k + 1] = c[jvar, kvar]\n",
    "            dm[k + 1, 0] = c[kvar, jvar]\n",
    "\n",
    "            for kk in range(irank):\n",
    "                kkvar = int(imp[kk])\n",
    "                dm[k + 1, kk + 1] = c[kvar, kkvar]\n",
    "\n",
    "        return dm\n",
    "\n",
    "    nrow, ncol = d.shape\n",
    "\n",
    "    dl = np.zeros((nrow, ncol))\n",
    "    imp = np.zeros(nr)\n",
    "    mp = np.zeros(nr)\n",
    "\n",
    "    w = np.zeros((nr, ncol))\n",
    "    p = np.zeros((nr, ncol))\n",
    "    s = np.zeros((nr, ncol))\n",
    "\n",
    "    error = error / 100\n",
    "    mean = np.mean(d, axis=0)\n",
    "    error = np.max(mean) * error\n",
    "\n",
    "    s[0, :] = np.std(d, axis=0)\n",
    "    w[0, :] = (s[0, :] ** 2) + (mean**2)\n",
    "    p[0, :] = s[0, :] / (mean + error)\n",
    "\n",
    "    imp[0] = int(np.argmax(p[0, :]))\n",
    "    mp[0] = p[0, :][int(imp[0])]\n",
    "\n",
    "    l = np.sqrt((s[0, :] ** 2) + ((mean + error) ** 2))\n",
    "\n",
    "    for j in range(ncol):\n",
    "        dl[:, j] = d[:, j] / l[j]\n",
    "\n",
    "    c = np.dot(dl.T, dl) / nrow\n",
    "\n",
    "    w[0, :] = w[0, :] / (l**2)\n",
    "    p[0, :] = w[0, :] * p[0, :]\n",
    "    s[0, :] = w[0, :] * s[0, :]\n",
    "\n",
    "    print(\"purest variable 1: \", int(imp[0] + 1), mp[0])\n",
    "\n",
    "    for i in range(nr - 1):\n",
    "        for j in range(ncol):\n",
    "            dm = wmat(c, imp, i + 1, j)\n",
    "            w[i + 1, j] = np.linalg.det(dm)\n",
    "            p[i + 1, j] = w[i + 1, j] * p[0, j]\n",
    "            s[i + 1, j] = w[i + 1, j] * s[0, j]\n",
    "\n",
    "        imp[i + 1] = int(np.argmax(p[i + 1, :]))\n",
    "        mp[i + 1] = p[i + 1, int(imp[i + 1])]\n",
    "\n",
    "        print(\"purest variable \" + str(i + 2) + \": \", int(imp[i + 1] + 1), mp[i + 1])\n",
    "\n",
    "    sp = np.zeros((nrow, nr))\n",
    "\n",
    "    for i in range(nr):\n",
    "        sp[0:nrow, i] = d[0:nrow, int(imp[i])]\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(sp)\n",
    "    plt.title(\"Estimate Components\")\n",
    "\n",
    "    concs = np.dot(np.linalg.pinv(sp), d)\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    for i in range(nr):\n",
    "        plt.plot(concs[i])\n",
    "    plt.title(\"Concentrations\")\n",
    "    plt.show()\n",
    "\n",
    "    return sp, concs\n",
    "\n",
    "\n",
    "m_d111_subset_aug = m_d111_subset.pivot_table(\n",
    "    columns=\"wavelength\", index=\"i\", values=\"scale_center\"\n",
    ")\n",
    "# Run Simplisma\n",
    "sp, concs = simplisma(m_d111_subset_aug.values, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m_d111_subset_aug);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d111_subset_aug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pymcr.mcr import McrAR\n",
    "from pymcr.constraints import ConstraintNonneg, ConstraintNorm\n",
    "\n",
    "logger = logging.getLogger(\"pymcr\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# StdOut is a \"stream\"; thus, StreamHandler\n",
    "stdout_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "\n",
    "mcrar = McrAR(\n",
    "    max_iter=100,\n",
    "    st_regr=\"OLS\",\n",
    "    c_regr=\"OLS\",\n",
    "    c_constraints=[ConstraintNonneg(), ConstraintNorm()],\n",
    "    tol_increase=1e4,\n",
    "    tol_n_above_min=10,\n",
    ")\n",
    "mcrar.fit(D=m_d111_subset_aug, ST=sp.T, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copt = mcrar.C_opt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m_d111_subset_aug);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copt = pd.DataFrame(copt)\n",
    "copt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_copt = copt.melt(var_name=\"column\", value_name=\"conc\")\n",
    "m_copt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mcrar.C_opt_.dot(mcrar.ST_opt_).T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(\n",
    "    mcrar.C_opt_.dot(mcrar.ST_opt_),\n",
    "    columns=m_d111_subset_aug.columns,\n",
    "    index=m_d111_subset_aug.index,\n",
    ")\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d111_subset_aug.reset_index().melt(\n",
    "    var_name=\"wavelength\", id_vars=\"i\", value_name=\"abs\"\n",
    ").groupby(\"wavelength\").get_group(\"256\")[\"abs\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_out = out.reset_index().melt(var_name=\"wavelength\", id_vars=\"i\", value_name=\"abs\")\n",
    "melt_out.groupby(\"wavelength\").get_group(\"256\")[\"abs\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_out = melt_out.fillna(0)\n",
    "melt_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = plt.tricontourf(melt_out.wavelength, melt_out.i, melt_out[\"abs\"], level=10)\n",
    "artists, labels = cc.legend_elements()\n",
    "plt.legend(artists, labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = \"/Users/jonathan/mres_thesis/wine_analysis_hplc_uv/src/wine_analysis_hplc_uv/notebooks/pca_sample.parquet\"\n",
    "m_d111_subset_aug.to_parquet(opath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
