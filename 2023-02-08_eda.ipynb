{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0449ca91-a805-45f2-9eaf-ddc3ab2a71ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.130661Z",
     "iopub.status.busy": "2023-02-10T02:27:45.129437Z",
     "iopub.status.idle": "2023-02-10T02:27:45.149430Z",
     "shell.execute_reply": "2023-02-10T02:27:45.146255Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.130618Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonathan/002_0_jono_data\n"
     ]
    }
   ],
   "source": [
    "# get list of directories containing data to form datadir objects\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "os.chdir(\"/Users/jonathan/002_0_jono_data/\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c767a1-6de1-4441-aa93-004293634a46",
   "metadata": {},
   "source": [
    "To distinguish between single run directories and sequence directories, easiest way is to identify whether they contain a `.S` file. They appear to be semi-encoded files containing the sequence information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6683632a-6066-423d-8fb2-30c76799c25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:29:29.195249Z",
     "iopub.status.busy": "2023-02-10T02:29:29.194900Z",
     "iopub.status.idle": "2023-02-10T02:29:29.202740Z",
     "shell.execute_reply": "2023-02-10T02:29:29.202171Z",
     "shell.execute_reply.started": "2023-02-10T02:29:29.195224Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# seperate single runs and sequences into seperate lists\n",
    "\n",
    "from dir_ext_set_getter import dir_ext_set_dict_builder\n",
    "\n",
    "root_dir = \"/Users/jonathan/002_0_jono_data/\"\n",
    "\n",
    "# iterate through the list \n",
    "\n",
    "#print(\"START DIRECTORY\")\n",
    "\n",
    "root_dir_list = os.listdir(root_dir)\n",
    "\n",
    "print(len(root_dir_list))\n",
    "\n",
    "ext_set_dict = dir_ext_set_dict_builder(root_dir, root_dir_list)\n",
    "\n",
    "print(len(ext_set_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1befdbd-a721-40f9-9773-864140f8ed1a",
   "metadata": {},
   "source": [
    "To ID the sequence directories, I need to identify unique characteristics between them and the single run data directories. Easiest way to survey the mass of dirs at hand is to form a list of each unique extension in the folder, then compare .S, .D, and others to identify if there is any variation, and what can be the identifier.\n",
    "\n",
    "[This blog post](https://www.digitalocean.com/community/tutorials/get-unique-values-from-a-list-in-python) suggests using `set()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb5d4d-52c4-4f03-8488-aa5062cd5165",
   "metadata": {},
   "source": [
    "Sets can be compared using set rules such as union, interseciton etc. THe most interesting thus far, in this [Medium](https://betterprogramming.pub/a-visual-guide-to-set-comparisons-in-python-6ab7edb9ec41) article, is `.symmetric_difference()` which returns the unique items in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea62c1-8a44-4ab5-9cde-8727c226cb2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for item in ext_set_dict.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa80b03-a6de-4104-aa0e-761945f7cda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.174493Z",
     "iopub.status.busy": "2023-02-10T02:27:45.174243Z",
     "iopub.status.idle": "2023-02-10T02:27:45.177128Z",
     "shell.execute_reply": "2023-02-10T02:27:45.176771Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.174472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "combo = itertools.combinations(ext_set_dict.keys(), 2)\n",
    "\n",
    "combo = list(map(tuple, combo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63faad-493b-43c0-bbe3-0900a37facd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T22:15:37.234273Z",
     "iopub.status.busy": "2023-02-09T22:15:37.233935Z",
     "iopub.status.idle": "2023-02-09T22:15:37.237719Z",
     "shell.execute_reply": "2023-02-09T22:15:37.236831Z",
     "shell.execute_reply.started": "2023-02-09T22:15:37.234251Z"
    },
    "tags": []
   },
   "source": [
    "Now we have a list of all combos without replacement. Now to iterate through the list, access each set and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "676cd621-aea3-4e14-8e3c-7fe4e0eabd3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T03:01:12.305962Z",
     "iopub.status.busy": "2023-02-10T03:01:12.305610Z",
     "iopub.status.idle": "2023-02-10T03:01:12.318593Z",
     "shell.execute_reply": "2023-02-10T03:01:12.317882Z",
     "shell.execute_reply.started": "2023-02-10T03:01:12.305937Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17', '2023-02-07-WINES 2023-02-07 19-41-18') \n",
      "\n",
      "{'6MM_52MIN'} \n",
      "\n",
      "6MM_52MIN belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "\n",
      "###########################################\n",
      "\n",
      "('20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17', '20230123_COFFEE_TEST_1.D') \n",
      "\n",
      "{'S', 'XML', 'macaml', 'ch', 'D', '6MM_52MIN', 'txt'} \n",
      "\n",
      "S belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "XML belongs to 20230123_COFFEE_TEST_1.D\n",
      "macaml belongs to 20230123_COFFEE_TEST_1.D\n",
      "ch belongs to 20230123_COFFEE_TEST_1.D\n",
      "D belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "6MM_52MIN belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "txt belongs to 20230123_COFFEE_TEST_1.D\n",
      "\n",
      "###########################################\n",
      "\n",
      "('20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17', '20230123_WINE_TEST_GRAD_4.D') \n",
      "\n",
      "{'S', 'XML', 'macaml', 'ch', 'D', '6MM_52MIN', 'txt'} \n",
      "\n",
      "S belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "XML belongs to 20230123_WINE_TEST_GRAD_4.D\n",
      "macaml belongs to 20230123_WINE_TEST_GRAD_4.D\n",
      "ch belongs to 20230123_WINE_TEST_GRAD_4.D\n",
      "D belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "6MM_52MIN belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "txt belongs to 20230123_WINE_TEST_GRAD_4.D\n",
      "\n",
      "###########################################\n",
      "\n",
      "('20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17', '20220801_CAFFEINE_CAFFEINE_STANDARD_100PPM.D') \n",
      "\n",
      "{'M', 'S', 'XML', 'acaml', 'ch', 'D', '6MM_52MIN'} \n",
      "\n",
      "M belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "S belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "XML belongs to 20220801_CAFFEINE_CAFFEINE_STANDARD_100PPM.D\n",
      "acaml belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "ch belongs to 20220801_CAFFEINE_CAFFEINE_STANDARD_100PPM.D\n",
      "D belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "6MM_52MIN belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "\n",
      "###########################################\n",
      "\n",
      "('20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17', '2023-01-23_wine_degredation_study_data') \n",
      "\n",
      "{'M', 'B', 'S', 'LOG', 'REG', 'acaml', 'ini', 'D', '6MM_52MIN'} \n",
      "\n",
      "M belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "B belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "S belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "LOG belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "REG belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "acaml belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "ini belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "D belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "6MM_52MIN belongs to 20220801_CAFFEINE_QUANT_SEQ 2022-08-01 15-53-17\n",
      "\n",
      "###########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each pair contains a combination of two dict keys, formed from a combination without \n",
    "# replacement of all items in the data directory. Iterating through each pair in the combo list\n",
    "# then accessing the values of the dict (sets) to find items that they differ by, THEN identifying\n",
    "# which of the pair the differences belong to.\n",
    "\n",
    "# going to make a list of items belong to sequences and items belonging to data directories, \n",
    "# then compare those lists. Probably makes the prior combinations superfluous but I will use this\n",
    "# flow structure atm regardless.\n",
    "\n",
    "single_run_item_list = []\n",
    "\n",
    "sequence_item_list = []\n",
    "\n",
    "for pair in combo[0:5]:\n",
    "\n",
    "    difference = ext_set_dict[pair[0]].symmetric_difference(ext_set_dict[pair[1]])\n",
    "    \n",
    "    print(pair, \"\\n\")\n",
    "    if not difference:\n",
    "        print(\"no difference\\n\")\n",
    "    else:\n",
    "        print(difference, \"\\n\")\n",
    "        for item in difference:\n",
    "            if item in ext_set_dict[pair[0]]:\n",
    "                print(item, \"belongs to\", pair[0])\n",
    "            if item in ext_set_dict[pair[1]]:\n",
    "                print(item, \"belongs to\", pair[1])\n",
    "        \n",
    "                \n",
    "    print(\"\\n###########################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135329d4-2945-4faa-a03a-d157c2603a73",
   "metadata": {},
   "source": [
    "A cursory glance at the output above hints that none of the .D dirs differ from each other (expected). We can check this with a quick modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a148516-7c64-45f4-889c-39aa918fda8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T03:01:33.794018Z",
     "iopub.status.busy": "2023-02-10T03:01:33.793671Z",
     "iopub.status.idle": "2023-02-10T03:01:33.801513Z",
     "shell.execute_reply": "2023-02-10T03:01:33.800779Z",
     "shell.execute_reply.started": "2023-02-10T03:01:33.793992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "difference_list = []\n",
    "\n",
    "\n",
    "def combo_diff_printer(combo):\n",
    "    for idx, pair in enumerate(combo):\n",
    "\n",
    "        if \".D\" in pair[0] and \".D\" in pair[1]:\n",
    "\n",
    "            print(\"###########################################\\n\")\n",
    "\n",
    "            difference = ext_set_dict[pair[0]].symmetric_difference(ext_set_dict[pair[1]])\n",
    "\n",
    "            print( \"#\", idx, pair, \"\\n\")\n",
    "\n",
    "            if not difference:\n",
    "\n",
    "                print(\"no differences in subdirectories\\n\")\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print(difference, \"\\n\")\n",
    "\n",
    "\n",
    "                difference_list.append(\"item {} had a difference\".format(idx))\n",
    "\n",
    "                for item in difference:\n",
    "\n",
    "                    if item in ext_set_dict[pair[0]]:\n",
    "                        print(item, \"belongs to\", pair[0])\n",
    "                    if item in ext_set_dict[pair[1]]:\n",
    "\n",
    "                        print(item, \"belongs to\", pair[1])\n",
    "\n",
    "                    print(\"\\n\")\n",
    "\n",
    "        \n",
    "print(difference_list)\n",
    "if not difference_list:\n",
    "        \"no differences detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd62e2-9b52-45ba-a79a-0cf7447f0084",
   "metadata": {},
   "source": [
    "In the above, certain .D directories had large differences between them. After investigating the log files, I discovered that if they are an aborted run, they will not contain the following file types: 'acaml', 'txt', 'M', 'macaml', for example. This is a good way of differentiating between them. Of course, the best way is to delete the data file immediately. Straight off the bat, we can remove any .D subdirectories which do not contain those files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e70ce-a2fd-4a81-afdf-a04feb3dcc92",
   "metadata": {},
   "source": [
    "I can use the any operator to check a subdir list for any of the extensions listed above. For example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552f4e1-67be-4e93-89f0-3a526739f81f",
   "metadata": {},
   "source": [
    "How many .D dirs in the root dir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad2e542-8146-419e-babb-a2495da94991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.209557Z",
     "iopub.status.busy": "2023-02-10T02:27:45.209308Z",
     "iopub.status.idle": "2023-02-10T02:27:45.212737Z",
     "shell.execute_reply": "2023-02-10T02:27:45.212312Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.209537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "num_of_data_dirs = sum(\".D\" in item for item in root_dir_list)\n",
    "\n",
    "print(num_of_data_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216720ff-2fc8-4bd2-a4b3-302d70092ab6",
   "metadata": {},
   "source": [
    "How many files in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6be01ab-790e-44a4-ab4c-35a063da5bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.213582Z",
     "iopub.status.busy": "2023-02-10T02:27:45.213453Z",
     "iopub.status.idle": "2023-02-10T02:27:45.216367Z",
     "shell.execute_reply": "2023-02-10T02:27:45.216002Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.213567Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(root_dir_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bac457-c895-4420-8261-47fa34c729e7",
   "metadata": {},
   "source": [
    "So, 8 sequences, 25 data dirs, 33 objects in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038f2b92-f5f0-45d8-aa27-f548b01beb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.217029Z",
     "iopub.status.busy": "2023-02-10T02:27:45.216912Z",
     "iopub.status.idle": "2023-02-10T02:27:45.223851Z",
     "shell.execute_reply": "2023-02-10T02:27:45.223442Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.217017Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220801_CAFFEINE_CAFFEINE_STANDARD_100PPM.D\n",
      "20230123_WINE_TEST_GRAD_3.D\n",
      "20230123_COFFEE_TEST.D\n",
      "after filtering for 'acaml', list length is 3\n",
      "['LCDIAG.REG', 'RUN.LOG', 'SINGLE.B', 'DAD1A.ch', 'DAD1B.ch', 'DAD1C.ch', 'SAMPLE.XML', 'CSlbk.ini', 'SAMPLE.XML.bak']\n",
      "['RUN.LOG', 'SINGLE.B', 'SAMPLE.XML', 'CSlbk.ini', 'SAMPLE.XML.bak']\n",
      "['RUN.LOG', 'SINGLE.B', 'SAMPLE.XML', 'CSlbk.ini', 'SAMPLE.XML.bak']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "list_of_aborted_data_dirs = []\n",
    "\n",
    "def check_file_ext_in_subdir(item):\n",
    "    subdir_path = os.path.join(os.getcwd(), item)\n",
    "    \n",
    "    subdir_list = os.listdir(subdir_path)\n",
    "    \n",
    "#   if 'acaml' and 'txt' and 'M' and 'macaml' not in any(os.listdir(item_path)):\n",
    "\n",
    "# This condition returns 1 if acaml is found. i.e. completed run data.\n",
    "    \n",
    "    if any(\"acaml\" in file for file in subdir_list):\n",
    "#        print(item)\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "count = 0\n",
    "\n",
    "list_without_acaml = []\n",
    "\n",
    "\n",
    "# iterating through the root dir list, targeting .D directories, returns the result (0 or 1) and counts how\n",
    "# often a match occurs, then removes the item from the list if the match occurs.\n",
    "\n",
    "for item in root_dir_list:\n",
    "    \n",
    "    if \".D\" in item:\n",
    "        \n",
    "        result = check_file_ext_in_subdir(item)\n",
    "        \n",
    "        count += result\n",
    "        \n",
    "        if result == 0:\n",
    "        \n",
    "            print(item)\n",
    "            \n",
    "            list_without_acaml.append(item)\n",
    "            \n",
    "print(\"after filtering for 'acaml', list length is\", len(list_without_acaml))            \n",
    "            \n",
    "for item in list_without_acaml:\n",
    "    if \".D\" in item:\n",
    "        print(os.listdir(os.path.join(os.getcwd(),item)))\n",
    "        \n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba1808-0a27-41b2-a5b1-271eb8b01c47",
   "metadata": {},
   "source": [
    "This result would lead me to believe that there are 3 aborted single runs in the root dir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117aafe-c9ba-4553-bb61-8bc554073099",
   "metadata": {},
   "source": [
    "Now that I have some classifications, I would like to assemble everything into a data structure. Say a dict to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc23257f-5330-45a8-be0e-8fc4bb74896a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.224463Z",
     "iopub.status.busy": "2023-02-10T02:27:45.224341Z",
     "iopub.status.idle": "2023-02-10T02:27:45.774445Z",
     "shell.execute_reply": "2023-02-10T02:27:45.774114Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.224451Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  4\n",
       "1  2  5\n",
       "2  3  6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dict = {\"a\": [1,2,3], \"b\" : [4, 5, 6]}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(a_dict)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca81600-aa8f-42b4-a1f8-bba6419f9590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T01:37:12.447433Z",
     "iopub.status.busy": "2023-02-10T01:37:12.446813Z",
     "iopub.status.idle": "2023-02-10T01:37:12.453393Z",
     "shell.execute_reply": "2023-02-10T01:37:12.452833Z",
     "shell.execute_reply.started": "2023-02-10T01:37:12.447385Z"
    },
    "tags": []
   },
   "source": [
    "Just remove the aborted runs from the root_dir_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb52cdf-a14e-434a-8d25-e9529d249fca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:27:45.775298Z",
     "iopub.status.busy": "2023-02-10T02:27:45.775095Z",
     "iopub.status.idle": "2023-02-10T02:27:45.777808Z",
     "shell.execute_reply": "2023-02-10T02:27:45.777460Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.775286Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(root_dir_list))\n",
    "\n",
    "for items in list_without_acaml:\n",
    "    root_dir_list.remove(items)\n",
    "    \n",
    "print(len(root_dir_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67e8c1-260f-4451-9787-56de47bf223e",
   "metadata": {},
   "source": [
    "Now we can get back to the business at hand, investigating what can separate .D dirs from sequence dirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff9cfd4-0fa7-44e5-a56b-1159ea0c091a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T02:29:07.391854Z",
     "iopub.status.busy": "2023-02-10T02:29:07.391300Z",
     "iopub.status.idle": "2023-02-10T02:29:07.400881Z",
     "shell.execute_reply": "2023-02-10T02:29:07.400348Z",
     "shell.execute_reply.started": "2023-02-10T02:29:07.391811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "dict_set_without_aborts = dir_ext_set_dict_builder(root_dir, root_dir_list)\n",
    "\n",
    "print(len(dict_set_without_aborts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48856d19-7631-4ec6-a478-58d74e1f91d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec9d21-6e2b-4066-9c1e-31721d33c1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a17ba1-9873-4bc7-97a7-b11312d49ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb562665-077c-44e4-8d81-77b56d32b269",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-10T02:27:45.869652Z",
     "iopub.status.idle": "2023-02-10T02:27:45.869814Z",
     "shell.execute_reply": "2023-02-10T02:27:45.869734Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.869725Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             if \".S\" in sub_obj:\n",
    "        \n",
    "#                 sub_dir_file_path = os.path.join(file_path, obj)\n",
    "                \n",
    "#                 sequences.append(sub_dir_file_path)\n",
    "            \n",
    "#             if \"SINGLE.B\" in sub_obj:\n",
    "                \n",
    "#                   y = 1\n",
    "                \n",
    "# #                 print(sub_dir_file_path)\n",
    "                \n",
    "# #                 sub_dir_file_path = os.path.join(file_path, obj)\n",
    "                \n",
    "# #                 single_runs.append(sub_dir_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33726e-fa12-4365-9bd3-0e16825e1f1a",
   "metadata": {},
   "source": [
    "Now start assembling a table of the runs and the sequences, seperately. To do this programmatically, the filenames need to be cleaned up and made consistant. First offender is the date formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a535f2-0818-4382-bb8f-f42639cbc97b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-10T02:27:45.870488Z",
     "iopub.status.idle": "2023-02-10T02:27:45.870735Z",
     "shell.execute_reply": "2023-02-10T02:27:45.870639Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.870629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for item in single_runs:\n",
    "    \n",
    "    split_item = item.split(\"/\")\n",
    "    \n",
    "    print(split_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbe9c2-6987-4c6c-aced-c11a571feb2c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-10T02:27:45.871413Z",
     "iopub.status.idle": "2023-02-10T02:27:45.871652Z",
     "shell.execute_reply": "2023-02-10T02:27:45.871495Z",
     "shell.execute_reply.started": "2023-02-10T02:27:45.871486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for item in single_runs:\n",
    "    \n",
    "#     item_basename = os.path.basename(item)\n",
    "    \n",
    "#     split = item_basename.split('_')\n",
    "    \n",
    "#     if \"-\" not in split[0]:\n",
    "        \n",
    "#         no_dash_format = split[0]\n",
    "        \n",
    "#         year = no_dash_format[:4]\n",
    "\n",
    "#         month = no_dash_format[4:6]\n",
    "        \n",
    "#         day = no_dash_format[6:8]\n",
    "        \n",
    "#         dash_format = year + \"-\" + month + \"-\" + day\n",
    "    \n",
    "#         dash_format_item_basename = \"_\".join(split)\n",
    "        \n",
    "#         parent_dir_path = item.split(\"/\")\n",
    "        \n",
    "#         print(parent_dir_path)\n",
    "            \n",
    "# #       os.rename(item, dash_format_item_basename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44056472-29db-4589-9557-7900a904a666",
   "metadata": {},
   "source": [
    "2023-02-10-14:02 Tools that I need to continue the project are:\n",
    "\n",
    "A function to form a dict of directories and their children and display in a readable format.\n",
    "\n",
    "A function to form a combination size 2 without replacement of the keys of a given dictionary.\n",
    "\n",
    "A function to describe the symmetric difference between each member of each combination.\n",
    "\n",
    "Define each function from scratch individually, plug them together.\n",
    "\n",
    "for a given FILTERED directory list:\n",
    "\n",
    "    1. form a dict of sub directory names and children, return the dict list.\n",
    "    2. form a combination size 2 from the keys of the list of dicts, return combination.\n",
    "    3. display the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dece8a6-7bcd-437c-a1bb-0aa16a604d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9c4be-977f-40b1-b3d7-1b112f79e544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine_analysis_hplc_uv_venv",
   "language": "python",
   "name": "wine_analysis_hplc_uv_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
