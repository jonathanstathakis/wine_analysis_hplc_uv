{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer to [2023-03-08_logbook](/Users/jonathan/001_obsidian_vault/2023-03-08_logbook.md)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Wavelength of Absorbance Maxima Outside of Mobile Phase Region of Wines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to:\n",
    "\n",
    "- [x] Isolate the sequences and runs which used the avantor column.\n",
    "- [ ] Identify the wavelength region of 'minimal' baseline.\n",
    "- [ ] Identify the single wavelength with maximal absorbance within that region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to set up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "# adds root dir 'wine_analyis_hplc_uv' to path.\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "from agilette import agilette_core as ag\n",
    "\n",
    "lib = ag.Agilette('/Users/jonathan/0_jono_data').library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df = lib.data_table().applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "lib_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Avantor Column Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_runs = lib_df[lib_df['method'].str.contains('avantor')]\n",
    "avantor_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_runs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_runs.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good so far! 63 runs to play with, apparently only 42 are unique. Interesting. What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_runs_dup_df = avantor_runs[avantor_runs.duplicated(subset = ['names'], keep = False)]\n",
    "avantor_runs_dup_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates in name column are occuring simply because I'm running the same sample multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaching Baseline Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there is a question of baseline analysis. Let's begin as usual by lecting one data set, creating a process for that one, then generalising to all. Let's do 2021-debortoli-cabernet-merlot_avantor. First q: how do we interface between the data table and the rest of Agilette? feed the pathname back in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_run = avantor_runs[(avantor_runs['names'] == \"2021-debortoli-cabernet-merlot_avantor\") & (avantor_runs.index == '2023-02-23 12:21:12')]['path']\n",
    "\n",
    "the_run.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_uv_data = wine_run_dir.get_uv_data()\n",
    "wine_uv_data.extract_uv_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_uv_data.uv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_uv_data.line_plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weirdly, it appears to skip 216 - 220nm. Is another dataset the same? Rather than creating another plot, we can pull the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating a 3d Plot Bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_index_214 = wine_uv_data.uv_data.columns.to_list().index(214)\n",
    "\n",
    "next_nm = wine_uv_data.uv_data.columns[start_index_214 + 1]\n",
    "\n",
    "for x in range(0,5):\n",
    "    print(wine_uv_data.uv_data.columns[start_index_214 + x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wavelength columns are definitely in the uv dataframe. Why arn't they plotting? Maybe try plotting directly on the uv_data first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.core_scripts.hplc_dad_plots import plot_3d_line\n",
    "\n",
    "plot_3d_line(wine_uv_data.uv_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works OK when pltoted on directly, which means its something that happens in between extracting the UV data and passing it to the plot method in UV_Data class. However, on inspection it doesnt appear that there is anything that could cause that, so i'll just ignore it for now..\n",
    "\n",
    "Now to functionalise the above to be able to iterate over the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of runs to iterate over\n",
    "\n",
    "run_path_list = [x for x in avantor_runs['path']]\n",
    "run_path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(run_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the UV data for all Avantor runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_run = avantor_runs[(avantor_runs['names'] == \"2021-debortoli-cabernet-merlot_avantor\") & (avantor_runs.index == '2023-02-23 12:21:12')]['path']\n",
    "\n",
    "def wine_uv_extractor(run_path):\n",
    "    \"\"\"\n",
    "    For the given runs, extract the uv_data for further analysis\n",
    "    \"\"\"\n",
    "    wine_run_dir = lib.all_data_files[run_path] \n",
    "\n",
    "    wine_uv_data = wine_run_dir.get_uv_data().extract_uv_data()\n",
    "\n",
    "    return wine_uv_data\n",
    "\n",
    "for x in run_path_list:\n",
    "    wine_uv_extractor(x.name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a List of all .D Files Available"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am encountering a problematic issue here. I am trying to form a combined dict of single run data dir objects and sequence data dir objects. The core object is Run_Dir.\n",
    "\n",
    "In Sequence, the structure is as follows:\n",
    "\n",
    "`Sequence.data_files = {'run_dir_name' : Run_Dir}`\n",
    "\n",
    "One method could be implemented with the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "seq_run_dict = {}\n",
    "\n",
    "for sequence_key in lib.sequences.keys():\n",
    "    #print(sequence_key)\n",
    "    for run_key in lib.sequences[sequence_key].data_files.keys():\n",
    "\n",
    "        #print(f\"\\t{run_key}\")\n",
    "\n",
    "        run_key_list = []\n",
    "\n",
    "        if run_key not in run_key_list:\n",
    "            run_key_list.append(run_key)\n",
    "        else:\n",
    "            print(f\"\\t{run_key} is a duplicate\")\n",
    "\n",
    "        # handling duplicates by adding a counter, or incrementing the last counter if there isnt one already. The problem is that a common name is 0001, for example. How do I add a counter to that?\n",
    "\n",
    "        # if pattern *_[0-9] at the end of the key, increment the last number by 1, else add _1 to the end of the key.\n",
    "\n",
    "        if re.search(r'_[0-9]$', run_key):\n",
    "            key_prefix, suffix = run_key.rsplit('_',1)\n",
    "            new_suffix = str(int(suffix) + 1)\n",
    "            new_key = f'{key_prefix}_{new_suffix}'\n",
    "\n",
    "            print(new_key)\n",
    "        else:\n",
    "            new_key = f'{run_key}_1'\n",
    "\n",
    "        run = lib.sequences[sequence_key].data_files[run_key]\n",
    "        seq_run_dict[new_key] = run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq_run_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Dict Implementation Deleting Duplicate named runs?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this line of inquiry has led me to question whether using dicts as a fundamental data structure is causing duplicates to be ignored. I will investigate this by using Unix find and grep in the following manner:\n",
    "\n",
    "`find . -type d -name \"*.D\" -not -name \".DS_Store\" | grep -c \".D$\"`\n",
    "\n",
    "The result is 110 directories.\n",
    "\n",
    "This was verified by checking the paths of each file counted, and noting that the paths were indeed unique.\n",
    "\n",
    "`find . -type d -name \"*.D\" -not -name \".DS_Store\" -print | tee >(wc -l)`\n",
    "\n",
    "Considering that the paths are unique, and that the sequence data dirs are constructed WITHIN the sequence object, I think I can safely say that no duplicates are being lost. It is however a messy problem, one that needs to be solved later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lib.single_runs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(seq_run_dict) + len(lib.single_runs.keys())\n",
    "total_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it's 13 runs short. Sounds suspiciously like its missing one of the initial wine runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Missing Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_run_dict['0091_1'].acq_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the original one. What about the run, what two weeks later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in lib.sequences.keys():\n",
    "    print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears to be duplicating MOST of the sequences.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_file in lib.sequences['2023-02-15_WINES_2023-02-15_15-19-53.sequence'].data_files:\n",
    "    print(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing 'Empty' Sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 3 are empty:\n",
    "\n",
    "2023-02-07_WINES.sequence:\n",
    "2023-02-07-WINES.S METHODS.REG\n",
    "\n",
    "2023-02-15_WINES_2023-02-15_15-08-23.sequence:\n",
    "2023-02-15_WINES.S METHODS.REG\n",
    "\n",
    "2023-02-15_WINES_2023-02-15_15-18-24.sequence.\n",
    "\n",
    "Remove them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have run '/Users/jonathan/wine_analysis_hplc_uv/scripts/remove_empty_sequences.py' to remove the empty sequences. Now what about the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in lib.sequences.keys():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the Avantor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence_key in sorted(lib.sequences.keys(), reverse = True):\n",
    "    print(lib.sequences[sequence_key])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can drop '2023-02-07-WINES.sequence' because that's the run which didnt pump mobile phase through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_runs = avantor_runs[avantor_runs['sequence'] != '2023-02-07-WINES.sequence']\n",
    "avantor_runs.style.set_properties(**{'max-height': '200px', 'max-width': '800px', 'overflow': 'scroll'})\n",
    "\n",
    "avantor_runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
