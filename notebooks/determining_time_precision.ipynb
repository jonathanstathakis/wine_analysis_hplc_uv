{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "from wine_analysis_hplc_uv import definitions\n",
    "from wine_analysis_hplc_uv.db_methods import get_data, pivot_wine_data\n",
    "import pandas as pd\n",
    "import duckdb as db\n",
    "\n",
    "#pd.options.display.width = None\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 15\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.colheader_justify = \"left\"\n",
    "\n",
    "con = db.connect(definitions.DB_PATH)\n",
    "def fetch_dataset(con):\n",
    "    get_data.get_wine_data(con, detection=('cuprac',), wavelength=(450,), varietal=('shiraz',))\n",
    "    df = pivot_wine_data.pivot_wine_data(con)\n",
    "    return df\n",
    "\n",
    "df154 = (fetch_dataset(con)\n",
    "         .loc[:,pd.IndexSlice['154', :,['mins','value']]]\n",
    "         .stack(['samplecode','wine'])\n",
    "         .reset_index()\n",
    "         .set_index([\"mins\",'samplecode','wine'])\n",
    "         .unstack(['samplecode','wine'])\n",
    "         .reorder_levels(['samplecode','wine','vars'], axis=1)\n",
    "         #.pipe(lambda df: df.set_index(pd.to_timedelta(df.index, unit='minutes')))\n",
    "         \n",
    "         \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the Precision of Spectrum Chromatogram Observations in my Dataset\n",
    "\n",
    "There is question of what is the precision of the time points of my observations. For example, sample 154:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df154.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the second time point of this sample is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = (\n",
    "    df154\n",
    "    .index.to_frame().astype(str).iat[1,0]\n",
    ")\n",
    "print(obs)\n",
    "print(\"num sigfigs:\", len(obs.split(\".\")[1]))\n",
    "#.split('.')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Unfortunately even the 'raw' data in my database has a precision of sometimes 18 digits, which could not possibly be correct, and must be a symptom of float datatypes in Python. To settle this once and for all, I could either make a decision of what is the minimum time scale that retains unique values in the time column, or check a .UV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rainbow as rb\n",
    "import os\n",
    "filepath = os.path.join(definitions.LIB_DIR,\"cuprac\",\"131.D\")\n",
    "obs = rb.read(filepath).get_file('DAD1.UV').xlabels[0]\n",
    "print(obs)\n",
    "print(\"num sigfigs:\",len(str(obs).split(\".\")[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well I have been vindicated, as rainbow is also returning 18 significant figures. Thus the second approach is required - identify an appropriate level of granularity by testing several time scales and seeing when duplicate values appear. Observe the millisecond ('L') and second ('S') scales (refer to [offset alias](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases) for the symbology):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df154_ = df154.pipe(lambda df: df.set_index(pd.to_timedelta(df.index, unit=\"minutes\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df154_\n",
    "    .index[df154_.index\n",
    "    .round(freq=\"L\")\n",
    "    .duplicated()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df154_\n",
    "    .index[df154_.index.round(freq='S')\n",
    "           .duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that no duplicates are detected at the millisecond scale ('L') , however at the second ('S') scale, over half the observation points are now duplicates. Thus we will continue at the millisecond scale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
