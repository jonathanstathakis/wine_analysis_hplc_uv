{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing from [Identifying Optimal Wavelength](2023-03-14_identifying_optimal_wavelength.ipynb), I will use the methods developed there to aggregate the results for all 2.5% avantor runs thus far. Although presumably, this method should work for all methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pybaselines import Baseline\n",
    "\n",
    "# adds root dir 'wine_analyis_hplc_uv' to path.\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "from agilette import agilette_core as ag\n",
    "\n",
    "lib = ag.Agilette('/Users/jonathan/0_jono_data').library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df = lib.data_table()\n",
    "lib_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the leading in notebook, I will use the latest De Bertoli Cab Merlot sample `2023-03-07_DEBERTOLI_CS_001.D`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning the Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to do this is to stay within a DataFrame environment.\n",
    "\n",
    "1. Form a a DF of:\n",
    "run name | uv_data object.\n",
    "2. for each run: scale, baseline adjust, calculate average baseline gradient and peak heights, get the ratio. \n",
    "3. Plot the maxima of the above values for each run. Probably drop after 380nm. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = lib_df[(lib_df['method'].str.contains(\"2_1*\")) & ~(lib_df['sample_name'].str.contains(\"uracil*\")) & ~(lib_df['uv_files'].apply(len)==0)]\n",
    "\n",
    "runs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the runs_uv_data DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = lib.all_data()\n",
    "\n",
    "def uv_data_extractor(column):\n",
    "    data_dir = all_data[column]\n",
    "    uv_data = data_dir.load_spectrum().uv_data\n",
    "\n",
    "    return uv_data\n",
    "\n",
    "uv_data_series = runs['run_name'].apply(uv_data_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv = runs\n",
    "\n",
    "runs_uv['uv_data'] = uv_data_series\n",
    "\n",
    "runs_uv = runs_uv.drop(['uv_files', 'sequence', 'ch_files', 'sample_name', 'desc'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv['uv_data'].iloc[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv['uv_data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually iterating over each row in the top level df then each column in the uv_data df and applying fit_transform()\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# for idx, row in runs_uv.iterrows():\n",
    "#     for column in row['uv_data']:\n",
    "#         scaled_column = scaler.fit_transform(row['uv_data'][column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv.loc[3,'uv_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# How do I access an individual dataframe.\n",
    "\n",
    "uv_df_1 = runs_uv.loc[3,'uv_data']\n",
    "\n",
    "# test applying minmaxscaler to a single dataframe.\n",
    "\n",
    "scaled_uv = scaler.fit_transform(uv_df_1)\n",
    "scaled_uv_df = pd.DataFrame(scaled_uv, columns = uv_df_1.columns, index = uv_df_1.index)\n",
    "scaled_uv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it again\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def df_scaler(column):\n",
    "    scaled_column = scaler.fit_transform(column)\n",
    "\n",
    "    scaled_column = pd.DataFrame(scaled_column, columns = column.columns, index = column.index)\n",
    "        \n",
    "    return scaled_column\n",
    "    \n",
    "runs_uv['scaled_uv_data'] = runs_uv['uv_data'].apply(df_scaler)\n",
    "runs_uv['scaled_uv_data'][10]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling has been achieved successfully."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv.reset_index(drop = True)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs_uv_test = runs_uv.reset_index(drop = True)[0:1]\n",
    "\n",
    "def baseline_calculator(column):\n",
    "    baseline_fitter = Baseline(column.index)\n",
    "    baseline_y = baseline_fitter.iasls(column.values)\n",
    "\n",
    "    return (baseline_y[0])\n",
    "\n",
    "def get_cols(column):\n",
    "    baseline = column.apply(baseline_calculator)\n",
    "    return baseline\n",
    "\n",
    "runs_uv['scaled_baselines'] = runs_uv['scaled_uv_data'].apply(get_cols)\n",
    "\n",
    "runs_uv['scaled_baselines'][10]\n",
    "\n",
    "# runs_uv_test['scaled_baselines'] = runs_uv['scaled_uv_data'].apply(lambda col: col.apply(baseline_calculator))\n",
    "# runs_uv['scaled_baselines'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv['scaled_baselines'][10] - runs_uv['scaled_uv_data'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv['scaled_baselines'][10].drop('mins', axis = 1).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv['baseline_adjusted_uv_data'] = runs_uv['scaled_uv_data'] - runs_uv['scaled_baselines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_uv.loc[10, 'baseline_adjusted_uv_data'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Baseline Gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is calculated for each wavelength for each run. Thus the format of the data for each run should be nm | gradient average. Top level df can hold a column called `['av baseline gradients']`which can contain a df of the stated format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_av_grad(column):\n",
    "    grad = np.gradient(column)\n",
    "    av = np.mean(grad)\n",
    "    # returns a series with nm as index, avs as values.\n",
    "    return(av)\n",
    "\n",
    "runs_uv['av_baseline_grads'] = runs_uv['scaled_baselines'].‚àèdrop('mins').apply(lambda df: df.apply(calc_av_grad))\n",
    "\n",
    "runs_uv.loc[10, 'av_baseline_grads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
