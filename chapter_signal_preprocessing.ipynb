{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter - Signal Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter details my efforts to standardise a chromatographic dataset of timexintensity signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wine_analysis_hplc_uv import definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta\n",
    "\n",
    "Decisions reached during this analysis will be recorded here and in the project [README](../README.md#eda-decisions). Methods developed during this analysis will be formalized [here](../src/wine_analysis_hplc_uv/signal_processing/mindex_signal_processing.py) in a class that will provide methods of preprocessing the time axis for use in pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-Axis Characterization and Standardisation\n",
    "\n",
    "We were able to normalize all inter-sample time axes across the dataset and reduce to one universal time axis across the dataset by rounding to a millisecond scale and correcting for a scalar offset that started at time zero. More information can be found at [time_axis_characterisation_and_normalization](./src/wine_analysis_hplc_uv/notebooks/time_axis_characterisation_and_normalization.ipynb). Primarily, methods for normalizing can be found at [mindex_signal_processing](src/wine_analysis_hplc_uv/signal_processing/mindex_signal_processing.py) `.adjust_timescale` and `.correct_offset`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling of Chromatographic Time Series\n",
    "\n",
    "I have created a proof of concept of dataset compression at [downsampling_signals](./src/wine_analysis_hplc_uv/notebooks/downsampling_signals.ipynb) through downsampling from 2.5Hz to 0.5Hz without noticable loss of signal information. This showed that downsampling with mean aggregation reduced dataset size by 90% without noticable change in signal shape.  Whatsmore, I found that raw signals required an initial resampling to their current frequency to smooth out local irregularities, that 0 - 20 mins is the most interesting (and easiest to work with) range, and that Euclidean distance is an appropriate and intuitive measure of change during downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of 'Raw' Dataset\n",
    "\n",
    "For testing the preprocessing, I need to have a version of the dataset of state just prior to the processing. Hence I have created a test dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions.RAW_PARQ_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Downsampled Test Dataset\n",
    "\n",
    "Following the findings of [downsampling_signals](./src/wine_analysis_hplc_uv/notebooks/downsampling_signals.ipynb), I created a test dataset of 4 shiraz samples in parquet file format at [creating_downsampled_testset](./src/wine_analysis_hplc_uv/notebooks/creating_downsampled_testset.ipynb) after it was found that reading and writing to parquet was twice as fast as csv, and that parquet preserved the multiindexed nature of the dataframe. In this process, the time axis is corrected and rounded and the dataset is moved to a universal time index. The wine column level is also made unique by the addition of an ascending integer count. The filepath of the test dataset parquet file is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions.XPRO_DOWNSAMPLED_PARQ_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y-Axis Correction\n",
    "\n",
    "Utilizing the test dataset created [here](./src/wine_analysis_hplc_uv/notebooks/creating_downsampled_testset.ipynb), I have proceeded to develop a number of y-axis correction methods. As of 2023-09-04 13:39:25 this only includes subtraction of y[0] to set time zero to y=0. A 'processed' parquet file can be found at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions.XPRO_YPRO_DOWNSAMPLED_PARQ_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over time I expect more methods to be added to the above, at least a smoothing routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Correction\n",
    "\n",
    "General notes on baseline correction algorithms are currently (2023-09-04 13:48:23) being developed in [baseline_correction](./src/wine_analysis_hplc_uv/notebooks/baseline_correction.ipynb).\n",
    "\n",
    "\n",
    "A brief investigation on Backcor, a literature recommended baseline correction algorithm for chromatograms was undertaken in [backcor_on_sampleset](./src/wine_analysis_hplc_uv/notebooks/backcor_on_sampleset.ipynb). Without manually tweaking the parameters it was found to perform poorly on the dataset, especially at the ends.\n",
    "\n",
    "Following x and y axis preprocessing developed [here](././src/wine_analysis_hplc_uv/notebooks/time_axis_characterisation_and_normalization.ipynb) and [here](././src/wine_analysis_hplc_uv/notebooks/offset_and_scale_y_axis.ipynb) respectively, an investigation into the different baseline correction methods has been started in [developing_baseline_subtraction](././src/wine_analysis_hplc_uv/notebooks/developing_baseline_subtraction.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Smoothing\n",
    "\n",
    "A prefunctory investigation into the appliation of Savitzky-Golay smoothing has been started in [investigating_signal_smoothing](././src/wine_analysis_hplc_uv/notebooks/investigating_signal_smoothing.ipynb), but as of 2023-09-07 14:48:51 hasn't gotten very far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Signal Alignment via DTW\n",
    "\n",
    "2023-09-07 14:56:11\n",
    "\n",
    "The holy grail of this project is to apply [Dynamic Time Warping]() to a chromatographic dataset in order to align all peaks sample-by-sample. Efforts began in late April 2023 but faltered because the pipeline became unmaintainable. Five months later we're finally at a stage where we can begin again.\n",
    "\n",
    "The earlier sections of this chapter addressed basic signal preprocessing. Now, we need to produce a method of identifying the 'most similar' signal to all other signals in the set, then align on that signal.\n",
    "\n",
    "### Identifying Representative sample\n",
    "\n",
    "A method of identifying a representative sample as been established in [identifying_most_similar_signal](././src/wine_analysis_hplc_uv/notebooks/identifying_most_similar_signal.ipynb) and added to SignalProcessor as `most_correlated`. It uses the pandas built-in method `.corr` to construct a correlation matrix then return the samplecode idx object of the sample with the highest mean correlation.\n",
    "\n",
    "### DTW\n",
    "\n",
    "A method of applying DTW utilising `most_correlated` will be developed in [Dynamic Time Warping](././src/wine_analysis_hplc_uv/notebooks/dynamic_time_warping.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation of The Derivatives of Chromatographic signals\n",
    "\n",
    "It is well-known that the first and second derivatives of a chromatographic signal can be used for peak detection. [This notebook](./src/wine_analysis_hplc_uv/notebooks/derivatives_of_chromatograms.ipynb) is intended to investigate their behavior and see whether they can be useful in dashboard level signal visualisation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
