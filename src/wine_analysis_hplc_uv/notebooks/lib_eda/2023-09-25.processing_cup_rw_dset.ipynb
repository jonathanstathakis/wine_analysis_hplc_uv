{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Processing CUPRAC Red Wine Dataset\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is a demonstrative pipeline of the production of a processed Red Wine CUPRAC detection dataset at 450nm. The output will be a parquet file ready for feeding to sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: get a dataset of all cuprac reds and run them through the pipeline (gna need to adapt the downsampling into a classlike pipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wine_analysis_hplc_uv import definitions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wine_analysis_hplc_uv.notebooks.dtw_methods import DTWNotebookMethods, AlignPipe, RelPlotDFBuilder\n",
    "from wine_analysis_hplc_uv.old_signal_processing.mindex_signal_processing import (\n",
    "    SignalProcessor,\n",
    ")\n",
    "\n",
    "scipro = SignalProcessor()\n",
    "\n",
    "nb_mtds = DTWNotebookMethods()\n",
    "idx = pd.IndexSlice\n",
    "import duckdb as db\n",
    "from wine_analysis_hplc_uv.etl.build_library.db_methods import get_data, pivot_wine_data\n",
    "\n",
    "con = db.connect(definitions.DB_PATH)    \n",
    "\n",
    "get_data.get_wine_data(con=con, detection=('cuprac',), color=('red',), wavelength=(450,))\n",
    "\n",
    "rw_data = pivot_wine_data.pivot_wine_data(con)\n",
    "    \n",
    "rw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the dataset there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique samples from unique values of samplecode\n",
    "\n",
    "len(rw_data.columns.get_level_values('samplecode').unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unique samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 'mins' and 'value' for each sample and standardize the time axis for the dset\n",
    "\n",
    "d = rw_data.loc[:,idx[:,:,['mins','value']]].pipe(scipro.standardize_time)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # A number of samples will need to be eliminated. Produce an overlay plot via melt and convert time axis to float to observe bulk data shape\n",
    "\n",
    "rw_data = (\n",
    "        d   \n",
    "        .melt(ignore_index=False)\n",
    "        .reset_index().assign(mins=lambda df: df.mins.dt.total_seconds()/60)\n",
    "        )\n",
    "rw_data.pipe(sns.lineplot, x='mins',y='value',hue='samplecode')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need to remove those datasets that do not follow the general shape, defined as an average height greater than 25 between 5 and 10 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display the samples whose average height is less than 25 between 5 and 10 minutes.\n",
    "\"\"\"\n",
    "\n",
    "(rw_data\n",
    " .set_index('mins')\n",
    " .groupby(['samplecode']).filter(lambda x: x.loc[5.0:10.0,'value'].mean()<25)\n",
    " .pipe(lambda df: df if display(df.pipe(sns.lineplot, x='mins',y='value',hue='samplecode')) is None else df)\n",
    " );\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous studies, we will be removing the above displayed chromatograms from the sampleset as their profiles is deemed erroneous.\n",
    "\n",
    "|    | samplecode   |                           wine                          |\n",
    "|---:|:-------------|:--------------------------------------------------------|\n",
    "|  0 | 164          | 2015 yangarra estate old vine grenache                  |\n",
    "|  1 | 163          | 2015 yangarra estate shiraz mclaren vale                |\n",
    "|  2 | 128          | 2019 mount pleasant wines mount henry shiraz pinot noir |\n",
    "|  3 | 165          | 2020 izway shiraz bruce                                 |\n",
    "|  4 | ca0301       | 2021 chris ringland shiraz                              |\n",
    "|  5 | 161          | 2021 le juice fleurie fleurie gamay                     |\n",
    "|  6 | ca0101       | 2021 yering station pinot noir                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, these are not usable signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"use the samplecodes of th samples displayed above to remove them from the dataset. Using\n",
    "string literals to ensure a record of the samples identified as faulty in case something\n",
    "changes in the pipeline down the track.\n",
    "\n",
    "Display another overlay of the dataset to verify that all questionable signals are removed.\n",
    "\"\"\"\n",
    "\n",
    "samplecodes = ['164', '163', '128', '165', 'ca0301', '161', 'ca0101']\n",
    "\n",
    "rw_data = (rw_data\n",
    " .set_index('mins')\n",
    " .groupby(['samplecode']).filter(lambda x: ~x.samplecode.isin(samplecodes).any())\n",
    " .pipe(lambda df: df if display(df.pipe(sns.lineplot, x='mins',y='value',hue='samplecode')) is None else df)\n",
    " )\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to tidy format, index back to timedelta, resample to 2S intervals, run DTW alignment pipe, slice to 0-20 mins, then plot\n",
    "\n",
    "pro_data = (rw_data\n",
    " .pivot(columns=['samplecode','wine','vars'], values='value')\n",
    " .pipe(lambda df: df.set_axis(pd.TimedeltaIndex(df.index, unit='m')))\n",
    " .pipe(lambda df: df.resample(\"2S\").interpolate())\n",
    " .pipe(lambda df : AlignPipe().align_pipe(df, display=False))\n",
    " .loc[pd.to_timedelta(0,unit='m'):pd.to_timedelta(20, unit='m')]\n",
    ")\n",
    "\n",
    "pro_data.plot(legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently the alignment pipe marks the unaligned signal as 'query' and aligned as 'aligned'. As the reference does not require alignment there is no need to distinguish between the aligned and unaligned, but to retain symmetry, two signal columns were kept, both labelled 'ref'. Unfortunately that causes an error when trying to write to parquet. the code below removes the duplicate ref column.\n",
    "\n",
    "pro_data = pro_data.loc[:,~pro_data.columns.duplicated()]\n",
    "display(f\"num duplicate columns: {pro_data.columns.duplicated(keep='first').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store processed data to parquet file. \n",
    "pro_data.to_parquet(definitions.RW_CUP_450_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(definitions.RW_CUP_450_PROCESSED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated above, the dataset has been successfully written to and read from a parquet file at the specified filepath stored in the constant `definitions.RW_CUP_450_PROCESSED`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
