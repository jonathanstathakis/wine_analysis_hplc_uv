{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"DTW with python-dtw\"\n",
    "format: html\n",
    "date: 2023-08-18\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW with python-dtw\n",
    "\n",
    "! NOTE!\n",
    "\n",
    "2023-09-18 11:10:00: this code contains my attempts to use `python-dtw` , originally in [dynamic_time_warping](./dynamic_time_warping.ipynb). As the package is intended primarily to return distance metrics for classification (?) purposes, it proved difficult to extract the warping path, and I opted to use `dtwalign` instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explore the use of `dtw-python` for multiple signal alignment via DTW. It utilizes a representative sample method developed in [identifying_most_similar_signal](./identifying_most_similar_signal.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtw-python\n",
    "\n",
    "To use `dtw-python` , first we identify the reference sample, and then for every sample in the set, call `dtw` with `x` as the 'query', and `y` as the reference. This returns a `dtw` object for each sample which contains the results.\n",
    "\n",
    "In the `dtw-python` package there are a number of constraint parameters which control how the software behaves, including algorithm constraints for handling special cases.\n",
    "\n",
    "DTW alignment generally works by matching multiple elements in the query signal to one in the reference (compression(?)) or vice versa (stretching (?)). This behavior is handled by the `step_pattern` parameter.\n",
    "\n",
    "Within the package, `index1` and the y-axis (where relevent) refer to the query, and `index2` and the x-axis to the reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "from wine_analysis_hplc_uv import definitions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wine_analysis_hplc_uv.old_signal_processing.mindex_signal_processing import (\n",
    "    SignalProcessor,\n",
    ")\n",
    "\n",
    "scipro = SignalProcessor()\n",
    "df = pd.read_parquet(definitions.XPRO_YPRO_DOWNSAMPLED_PARQ_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the keys for the primary index in either format.\n",
    "\n",
    "sw_index = [\"samplecode\", \"wine\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First identify the reference sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whetehr scipro.most_correlated returns the expected value\n",
    "\n",
    "reference = df.pipe(scipro.most_correlated)\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the samplecode returned by `scipro.most_correlated` is the expected sample\n",
    "\n",
    "df[reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an aggregate dataframe of DTW objects for the sampleset\n",
    "\n",
    "# df =\n",
    "df_obj = (\n",
    "    df.pipe(\n",
    "        lambda df: df.stack([\"samplecode\", \"wine\"]) if df.columns.nlevels == 3 else df\n",
    "    )\n",
    "    .reorder_levels([\"samplecode\", \"wine\", \"mins\"])\n",
    "    .sort_index()\n",
    "    .groupby([\"samplecode\", \"wine\"])\n",
    "    .apply(lambda x: dtw(x=x, y=df.loc[:, reference]))\n",
    "    .to_frame(name=\"dtw_obj\")\n",
    ")\n",
    "df_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract index1 and index2 for each sample from the objects\n",
    "df_index1 = (\n",
    "    df_obj.groupby(sw_index)\n",
    "    .apply(lambda x: x[\"dtw_obj\"].values[0].index1)\n",
    "    .to_frame(name=\"index1\")\n",
    "    .explode(\"index1\")\n",
    "    .assign(i=lambda x: x.groupby(sw_index).cumcount())\n",
    "    .set_index(\"i\", append=True)\n",
    "    .rename_axis(\"vars\", axis=1)\n",
    "    .unstack(sw_index)\n",
    "    .reorder_levels(axis=1, order=[\"samplecode\", \"wine\", \"vars\"])\n",
    ")\n",
    "df_index1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are NaNs in all columns EXCEPT for torbreck struie 2. This is because it takes a lot more work to align that signal to the reference, but then when the groups are realigned, the elements not present in the other signals are filled with NA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much NA exactly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_index1.isna().groupby(sw_index, axis=1).sum().sum() / df_index1.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not an extreme amount to be honest. It appears that all the signals need significant work to align with the reference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not clear how to extract the aligned query series from the alignment process.\n",
    "\n",
    "this [stack overflow](https://stackoverflow.com/questions/25735766/understanding-dynamic-time-warping) post answer says that the `.indexn` contains the mapping, which is also what the documentation says, but what is not obvious is what I am supposed to do with it.\n",
    "\n",
    "A bit of rationalisation - if the indexes are the warping functions, and they are given as integer vectors, then they must be the elementwise mapping of query to reference, i.e. index2 is the method of mapping \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for index2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract index1 and index2 for each sample from the objects\n",
    "df_index2 = (\n",
    "    df_obj.groupby(sw_index)\n",
    "    .apply(lambda x: x[\"dtw_obj\"].values[0].index2)\n",
    "    .to_frame(name=\"index2\")\n",
    "    .explode(\"index2\")\n",
    "    .assign(i=lambda x: x.groupby(sw_index).cumcount())\n",
    "    .set_index(\"i\", append=True)\n",
    "    .rename_axis(\"vars\", axis=1)\n",
    "    .unstack(sw_index)\n",
    "    .reorder_levels(axis=1, order=[\"samplecode\", \"wine\", \"vars\"])\n",
    ")\n",
    "df_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index1.join(df_index2).sort_index(level=\"samplecode\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [@giorgino_2009], index1 is $\\phi(k)_x$, and index2 is $\\phi(k)_y$. If we 'apply' them by multiplying the original series by the vector, will we get the aligned signal?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first plot the reference signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create aligned signal by indexing original series by index1\n",
    "\n",
    "index1_154 = (df_index1.iloc[:, [0]]).dropna()\n",
    "\n",
    "index1_154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_154 = df.loc[:, [\"154\"]]\n",
    "original_154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index original 154 with corresponding index1\n",
    "fig, ax = plt.subplots(1)\n",
    "aligned_154 = original_154.iloc[index1_154.values.flatten()]\n",
    "display(aligned_154)\n",
    "aligned_154.plot(ax=ax)\n",
    "df[reference].plot(ax=ax)\n",
    "df[\"154\"].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing an Aligned Tensor\n",
    "\n",
    "Post-alignment we are expecting to output a tensor of sample series of the same length, aligned to the reference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got 1015 rows and we should have 600. Presumably there are duplicates now, the result of stretching. One method, mentioned by @tomasi2004 would be to aggregate by mean the repeat time points in the warped signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_154 = aligned_154.groupby(\"mins\").mean()\n",
    "aligned_154\n",
    "# aligned_154.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "aligned_154.plot(ax=ax)\n",
    "df[reference].plot(ax=ax)\n",
    "df[\"154\"].plot(ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least they are the same length now, however, the peak maxima is misaligned, which I would regard as the most vital landmark within the signals to align. Lets observe all of the samples..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index1 index element integers with time series values sourced from df\n",
    "\n",
    "\n",
    "def get_index(d):\n",
    "    r = df.index[d[\"index1\"]]\n",
    "    return r\n",
    "\n",
    "\n",
    "df_index1 = (\n",
    "    df_index1.stack([\"samplecode\", \"wine\"])\n",
    "    .assign(index1_td=lambda df: df.apply(get_index, axis=1))\n",
    "    .rename_axis(\"warp_func\", axis=1)\n",
    "    .unstack([\"samplecode\", \"wine\"])\n",
    "    .reorder_levels([\"samplecode\", \"wine\", \"warp_func\"], axis=1)\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "df_index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an index object with same levels and format as df\n",
    "\n",
    "df_index1_mins_index = (\n",
    "    df_index1.stack([\"samplecode\", \"wine\"])\n",
    "    .rename({\"index1_td\": \"mins\"}, axis=1)\n",
    "    .reset_index(\"i\", drop=True)\n",
    "    .set_index(\"mins\", append=True)\n",
    "    .index\n",
    ")\n",
    "\n",
    "df_index1_mins_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each sample and index with corresponding index1 then aggregate repeat time points\n",
    "# fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "a_df = (\n",
    "    df.stack([\"samplecode\", \"wine\"])\n",
    "    .reorder_levels([\"samplecode\", \"wine\", \"mins\"])\n",
    "    .assign(\n",
    "        aligned=lambda df: df.loc[df_index1_mins_index]\n",
    "        .groupby([\"samplecode\", \"wine\", \"mins\"])\n",
    "        .mean()\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename({\"value\": \"query\"}, axis=1)\n",
    ")\n",
    "a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "plot_df = (\n",
    "    a_df.set_index(\"samplecode\")\n",
    "    .rename({\"torbreck-struie\": \"tbs\"})\n",
    "    .reset_index()\n",
    "    .assign(wine=lambda df: df.samplecode + \"_\" + df.wine)\n",
    "    .set_index([\"wine\", \"mins\"])\n",
    "    .drop(\"samplecode\", axis=1)\n",
    "    .melt(ignore_index=False)\n",
    "    # .melt()\n",
    ")\n",
    "# df\n",
    "#  .unstack(['samplecode','wine'])\n",
    "#  .reorder_levels(['samplecode','wine','vars'],axis=1)\n",
    "#  .sort_index(axis=1)\n",
    "\n",
    "g = sns.FacetGrid(plot_df, col=\"vars\")\n",
    "g.map_dataframe(sns.lineplot, x=\"mins\", y=\"value\", hue=\"wine\", legend=True)\n",
    "g.add_legend()\n",
    "display(plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the expected aligned dataset is exactly the same as the original. This is because my approach of recompressing the stretched sections simply reverses the warping.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
