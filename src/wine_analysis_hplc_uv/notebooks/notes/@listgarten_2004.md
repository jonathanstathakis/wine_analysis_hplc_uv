---
* Authors: [[Jennifer Listgarten]], [[Radford Neal]], [[Sam Roweis]], [[Andrew Emili]]
* Date: [2004](2004)
* Cite key: listgarten_2004
, #zotero, #literature-notes, #reference
# Multiple Alignment of Continuous Time Series
---

## Links

[Homepage](mres_lit_review.md)
* [Local library](zotero://select/items/1_J7FZFTBL)
* [Cloud library](http://zotero.org/users/8278261/items/J7FZFTBL)

## Description

A MSA study proposing a novel HMM model with an example of application on TIC LC-MS 2D signal dataset.

## Summary

"Multiple Alignment of Continuous Time Series" by Listgarten et al. (2004) proposes a new approach to Multiple Series Alignment (MSA) of time series thorugh the development of an extension to the Hidden Markov Model (HMM) titled Continuous Profile Model (CPM). The CPM takes noisy signals and generates noiseless latent traces who are then aligned - the assumption being that all misalignment is contained in the noise. They propose that this is a solution to noisy, stocastic process signal alignment where there can be signal-on-signal variation in every axis. They applied this to both LC-MS 2D Total Ion Count (TIC) data (i.e. time x intensity chromatograms) and speech data with success in aligning both.

Importantly for me, their preprocessing procedure was as follows:

1. No smoothing
2. align all time series time axes so that their centroid is aligned to the median centroid of the set.
3. scale y so that each time series sum(y) = median sum(y) of dataset.
4. 1st shot alignment to gauge effectiveness.
5. Identify optimal smoothing parmater $\lambda$ through leave-one-out cross validation.
6. align again.

Note: no justification was made for these approaches.

The author concludes by stating that the model can be extended to n-dimensional alignments, and that applications include alignment of gene expression time profiles, temporal physiological signals, motion capture data, etc. Notably they state that it could be used to make use of one-shot data without replicates by including them in datasets of justifiably similar data to align on - the example they give is a signal from a dying patient that cannot be reproduced.

## Notes

* Mdnotes File Name: [@listgarten_2004](@listgarten_2004)

# Annotations

(17/08/2023, 10:42:04 am)

They name their model a "Continuous Profile Model" (CPM), a form of Hidden Markov Model (HMM).

> “When observing multiple time series generated by a noisy, stochastic process, large systematic sources of variability are often present. For example, within a set of nominally replicate time series, the time axes can be variously shifted, compressed and expanded, in complex, non-linear ways. Additionally, in some circumstances, the scale of the measured data can vary systematically from one replicate to the next, and even within a given replicate.”</span> <span 

Listgarten et al., 2004, p. 1</span>)</span> The authors pose the problem - how do you align multiple time series generated from a system with lots of inherent variation in every dimension?

> “The latent trace is an underlying, noiseless representation of the set of replicated, observable time series”

The CPM generates a latent trace from each time series - an idealized series of the signal data without noise

> “We have applied the CPM model to analyze several Liquid Chromatography - Mass Spectrometry (LC-MS) data sets from an experimental biology laboratory.”

The authors tested their CPM on LC-MS data

> "In our experiments we collapsed the data at each time point to one dimension by summing together abundance values over all mass/charge values. This one-dimensional data is referred to as the Total Ion Count (TIC).”

 They collapsed the 2nd order tensor time x m/z x intensity to time x intensity

> “First we trained the model with no smoothing (i.e., = 0) on the 13 replicates. This provided nice alignments when viewed in both the TIC space and the full two-dimensional space. Next we used leave-one-out cross-validation on six of the replicates in order to choose a suitable value for . Because the uk and dvk are time series specific, we ran a restricted EM on the hold-out case to learn these parameters, holding the other parameters fixed at the values found from learning on the training set. Sixteen values of over five orders of magnitude, and also zero, were used. Note that we did not include the regularization likelihood term in the calculations of hold-out likelihood. One of the non-zero values was found to be optimal (statistically significant at a p=0.05 level using a paired sample t-test to compare it to no smoothing).”

Process was as follows:

1. first no smoothing to roughly gauge effectiveness  
2. To estimate an optimal value of lambda, use leave-one-out-cross validation
  
Note: lambda is a smoothing parameter

“we pre-processed the LC-MS data set by coarsely aligning and scaling each time series as follows: We 1) translated each time series so that the center of mass of each time series was aligned to the median center of mass over all time series, 2) scaled the abundance values such that the sum of abundance values in each time series was equal to the median sum of abundance values over all time series. 

LC-MS data was preprocessed with the following:  
1. No smoothing
2. align all time series time axes so that their centroid is aligned to the median centroid of the set.
3. y was scaled so that each time series sum(y) = median sum(y) of dataset

> “For comparison, we also performed a linear warping of time with an offset. (i.e. each signal was translated so as to start at the same time, and the length of each signal was stretched or compressed so as to each occupy the same amount of time). Figure 1 shows the successful alignment of the speech signals by CPM and also the (unsuccessful) linear warp”</span> <span class="citation" data-citation="

Speech signals were also successfully aligned. The authors went as far as to crreate a set with a time offset, which was unable to be aligned.

> “DTW works on pairs of time series, aligning one time series to a specified reference time series. DTW does not take in to account systematic variations in the amplitude of the signal. Our CPM can be viewed as a rich and robust extension of DTW that can be applied to many time series in parallel and which automatically uncovers the underlying template of the data.”

Listgarten et al., 2004, p. 7</span>)</span> The proposed model is an extension of DTW.

“By training this model one can leverage information contained in noisy, replicated experimental data”

> “and obtain a single, superior resolution ’fusion’ of the data. We demonstrated successful use of this model on real data, but note that it could be applied to a wide range of problems involving time signals, for example, alignment of gene expression time profiles, alignment of temporal physiological signals, alignment of motion capture data, to name but a few.”

The authors conclude by stating that applications in clude alignment of gene expression time profiles, temporal physiological signals, motion capture data, etc.


