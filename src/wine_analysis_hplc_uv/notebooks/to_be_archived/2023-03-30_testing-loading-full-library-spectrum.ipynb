{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investgating Data Collection Progress Thus Far\n",
    "\n",
    "i.e. 2023-03-30."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to [2023-03-30_logbook](../../001_obsidian_vault/2023-03-31_logbook.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What Runs are Appropriate for Analysis.\n",
    "\n",
    "Criteria: \n",
    "\n",
    "1. were on the Avantor 10cm column.\n",
    "2. contain UV spectra.\n",
    "3. Not uracil, acetone or coffee runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from agilette.modules.library import Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = Library('/Users/jonathan/0_jono_data')\n",
    "df = lib.metadata_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try selecting only for rows that contain UV data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting UV Wine Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_df_avantor_wine_subset(df : pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df[(df['uv_filenames']!='') & (df['acq_method'].str.contains('AVANTOR')) & ~(df['name'].str.contains('uracil')) & ~(df['name'].str.contains('coffee')) & ~(df['name'].str.contains('lor'))]\n",
    "\n",
    "    return df\n",
    "\n",
    "avantor_df = metadata_df_avantor_wine_subset(lib.metadata_table)\n",
    "\n",
    "avantor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70 unique samples doesn't seem too bad. There should be more to pull sitting in the instrument as well. It appears that this filter is legitimate, as there is UV data for every remaining row.\n",
    "\n",
    "Now, one sticking point is that we don't have the wine names in this table. To get them we will need to load the sample tracker as a df and merge them on the sample ID., or 'name' in this dataframe. A further complicating factor is that the names are sometimes not consistant with sample tracker, for example '2021-debortoli-cabernet-merlot_avantor`. I dont believe it was ever added, and it makes up 7/107 of the runs. Let's first load sample_tracker then compare their contents."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Sample Tracker Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_tracker() -> pd.DataFrame:\n",
    "\n",
    "    from google_sheets_api import get_sheets_values_as_df\n",
    "\n",
    "    sheet_id = '15S2wm8t6ol2MRwTzgKTjlTcUgaStNlA22wJmFYhcwAY'\n",
    "    path_to_creds = '/Users/jonathan/wine_analysis_hplc_uv/credentials_tokens'\n",
    "\n",
    "    tracker_df = get_sheets_values_as_df(sheet_id, \"sample_tracker!A1:H200\", path_to_creds)\n",
    "\n",
    "    return tracker_df\n",
    "\n",
    "tracker_df = get_sample_tracker()\n",
    "# 2023-04-03-09-01 reading the local file today because I dont have internet.\n",
    "tracker_df = tracker_df.replace(\"\", np.nan)\n",
    "tracker_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making id/name Column the Same Prior to Join"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join `tracker_df` with `avantor_df` I need to do the following:\n",
    "1. Ensure they are the same datatype.\n",
    "2. Clear whitespace.\n",
    "3. Sort.\n",
    "4. Drop duplicates.\n",
    "5. Compare using `equals()`. If not, continue.\n",
    "\n",
    "1. Find common elements using `isin()`.\n",
    "2. filter on `isin()`.\n",
    "3. compare filtered columns using `equals()`.\n",
    "\n",
    "Credits: ChatGPT.\n",
    "\n",
    "I don't quite know how `filter` or `isin` works, so let's check it out.\n",
    "\n",
    "## `isin`\n",
    "\n",
    "`pd.DataFrame.isin` takes `values` as its argument, which can be any iterable, Series, DataFrame or dict, and returns a DataFrame of booleans depending on matches.\n",
    "\n",
    "For the given `values`, if any of the elements match an element of the DataFrame, a value of True is marked in the output DataFrame at that coordinate.\n",
    "\n",
    "The idea is to return a mask that can be applied to the original DataFrame.\n",
    "\n",
    "## `filter`\n",
    "\n",
    "`pd.DataFrame.filter` subsets the DataFrame rows and/or columns with an index-oriented approach, and the `like` keyword argument allows you to match column or row names against substrings and regex patterns for psuedo fuzzy matching.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the 'id' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the columns up, sort and drop duplicates\n",
    "\n",
    "def dataframe_cleaner(df : pd.DataFrame, col_name : str) -> pd.DataFrame:\n",
    "    df[col_name] = df[col_name].str.strip()\n",
    "    df = df.sort_values(col_name)\n",
    "    df = df.drop_duplicates(col_name)\n",
    "    return df\n",
    "    \n",
    "# todo: add subsetter to pipeline.\n",
    "avantor_df = (avantor_df.pipe(dataframe_cleaner, col_name='id'))\n",
    "tracker_df = (tracker_df.pipe(dataframe_cleaner, col_name='id'))\n",
    "\n",
    "tracker_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To form the link between `tracker_df` and `avantor_df`, I need to have an understanding of what happened when, and draw a link between sample dates, wine names, and ids. First though we can reconcile the formats of the id numbers. In tracker_df they have the format \"DD\" where D is a digit, but in avantor_df they are either empty, \"DD\" \"00DD\", or other. What methods are there of finding patterns in strings in a column?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Patterns in Strings in a Column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "for idx, row in tracker_df.iterrows():\n",
    "    print(row['id'], end=', ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tracker_df['id']` has pattern \"D\", \"DD\", or \"zD\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in avantor_df.iterrows():\n",
    "    print(row['id'], end=', ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantor DF starts with DDDD, goes to DD, then \"string\", DD, \"string\". Tbh there should be more DD after those, looks like im missing files? Anyway. To rectify this, we need to:\n",
    "1.  [x] pad tracker_df to be DD\n",
    "2. [x] drop the first and last digits on the first 19 rows of avantor df.\n",
    "3. replace the strings with DD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Padding Sample Tracker ID Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 Pad Tracker_DF to be DD. Can use `pd.Series.str.pad`\n",
    "\n",
    "def pad_id(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    return df['id'].str.pad(2, fillchar='0')\n",
    "\n",
    "tracker_df['id'] = pad_id(tracker_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Slicing 4 Digit ID's in `avantor_df`\n",
    "\n",
    "subset first 19 rows of avantor df (identify that group, probs by acq_date), drop first and last digits of id through slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_digit_ids = avantor_df[avantor_df['id'].str.len() ==4].sort_values('acq_date')\n",
    "\n",
    "# ranges from the 02-14 13:18:27 to 02-16 12:45:35. Is this the same as all values within that range?\n",
    "\n",
    "avantor_four_digit_id_range = avantor_df[(avantor_df['acq_date'] >= four_digit_ids.loc[four_digit_ids.index[0],'acq_date']) & (avantor_df['acq_date'] <= four_digit_ids.loc[four_digit_ids.index[-1],'acq_date'])].sort_values('acq_date')\n",
    "\n",
    "avantor_four_digit_id_range.equals(four_digit_ids)\n",
    "# confirmed that for those date ranges, all entries were four digit ids."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to perform the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_df['id'] = avantor_df['id'].apply(lambda x : x[2:4] if len(x)==4 else x)\n",
    "\n",
    "display(avantor_df[avantor_df['id'].str.len()==4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. replace the strings with DD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most difficult. First find all which are names rather than numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_mask = avantor_df['id'].str.isdigit()\n",
    "avantor_df[~(avantor_df['id'].str.isdigit())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df[tracker_df['name'].str.contains('crawford')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking \"sample_tracker\" for the 5 samples with string id's, I discovered that these 5 had never been logged. This is because at the time, they were just screening samples when I was worried that he column was damaged. Refer to [2023-02-21_logbook](file:///Users/jonathan/001_obsidian_vault/mres_logbook/2023-02-22_logbook.md).\n",
    "\n",
    "Simplest solution will be to enter them with new IDs.\n",
    "\n",
    "Note: can't update sample tracker until I get some internet. In the meantime just add them directly to the df. The names are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in avantor_df[~(avantor_df['id'].str.isdigit())].iterrows():\n",
    "    print(row['id'], end = \", \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because 'tracker_df.id' contains strings and string integers, I cannot sort properly. This is a secondary motivation for replacing the strings with integers. \"z3\" and \"NC\" are the main offenders, except that \"NC\" is not present in `tracker_df`, only `avantor_df`. \"z3\" will be replaced now with \"00\", as it was the first wine added to the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zema_mask = tracker_df['name'] == \"zema estate 'family selection' cabernet sauvignon\"\n",
    "\n",
    "tracker_df.loc[zema_mask,['id']] = '00'\n",
    "avantor_df.loc[avantor_df['id'] == 'z3', ['id']] = '00'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this manner, \"z3\" has been replaced by \"00\" in both `tracker_df` and `avantor_df`. The next step is to identify what the next available ID number is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(avantor_df['id'].describe())\n",
    "display(tracker_df['id'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale\n",
    "\n",
    "dtale.show(tracker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df['id'] = tracker_df['id'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df[tracker_df.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tracker_df[tracker_df['id'].str.isdigit()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the next id available is 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_df[~(avantor_df['id'].str.isdigit())].sort_values('acq_date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to:\n",
    "\n",
    "1. add wines to sample_tracker.\n",
    "2. rename wines in avantor_df.\n",
    "\n",
    "The fields I need in tracker_df are: 'id', 'vintage', 'name', 'sample_date', 'open_date'.\n",
    "\n",
    "Sample date is acq_date.\n",
    "\n",
    "1. [x] Make a new df from tracker_df with the wines that are not digit id. In that df get:\n",
    "    1. acq_date.\n",
    "    2. id\n",
    "2. [x] Add a column with the proper name based on fuzzy searching on tracker_df 'name'.\n",
    "3. [x] Add a col 'id_new' with with range >72.\n",
    "3. [ ] Add 'name', 'id', 'acq_date' to tracker_df, concat vertically.\n",
    "4. [ ] rename id in avantor_df with id_new.\n",
    "    \n",
    "Fuzzy match function detailed [here](2023-03-28-joining-cellartracker-metadata.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ids = avantor_df[~(avantor_df['id'].str.isdigit())][['acq_date', 'id']]\n",
    "string_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ids = string_ids.rename({'id' : 'exp_id'}, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df[tracker_df['name'].str.contains('stoney')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawford = [2018, \"crawford river cabernets\", 73]\n",
    "hey_malbec = [2020, \"matias riccitelli hey malbec\", 74]\n",
    "stoney_rise_pn = [2021, \"stoney rise pinot noir\", 75]\n",
    "koerner_nielluccio = [2021, 'koerner wine nielluccio sangiovese', 76]\n",
    "debortoli = [2021, 'De Bertoli Sacred Hill Cabernet Merlot', 77]\n",
    "nocturne  = [2021, 'Nocturne Cabernet', 78]\n",
    "\n",
    "wines_to_add = pd.DataFrame([crawford, hey_malbec, koerner_nielluccio,stoney_rise_pn, debortoli, nocturne], columns = ['vintage', 'name', 'id'])\n",
    "wines_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ids = string_ids.rename({'id':'exp_id'}, axis = 1)\n",
    "string_ids['new_id'] = [77,73,73,77,74,76,76,78,75]\n",
    "string_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(string_ids, wines_to_add, left_on = 'new_id', right_on = 'id')\n",
    "merge_id = merge_df.drop('id', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df = tracker_df.drop('Unnamed: 0', axis =1)\n",
    "tracker_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_id = merge_id.rename({\"new_id\":\"id\"}, axis = 1)\n",
    "merge_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df = tracker_df.rename({'new_id':'id'}, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracker_df.columns)\n",
    "print(merge_id.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.DataFrame.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_id['acq_date'] = merge_id['acq_date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df = tracker_df.rename({\"sample_date\":\"acq_date\"}, axis =1)\n",
    "\n",
    "tracker_df = tracker_df.append(merge_id[['id', 'vintage','name', 'acq_date']], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_2 = pd.merge(avantor_df, string_ids, left_on='id', right_on = 'exp_id', how = 'left')\n",
    "merge_df_2['id'] = merge_df_2['new_id'].fillna(merge_df_2['id'])\n",
    "merge_df_2 = merge_df_2.drop(columns=['new_id'])\n",
    "merge_df_2.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "27c46f4eb3a1e072bb472673e0f5bc67d135295985dc85bce54a4088e8c57ef4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
