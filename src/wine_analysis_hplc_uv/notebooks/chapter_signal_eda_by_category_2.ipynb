{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-10-18 Due to the fact that I am prototyping a lot of code and changing approaches (multiindex column default to long defaul primarily), literate progrmaming style is failing, re. version one of this notebook is somewhat unsalvagable - a testament to why rushing always fails in the end. At some point I'll have to go through and fix it. in the meantime, copy code over and push ON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dtwalign import dtw\n",
    "import pandas as pd\n",
    "from wine_analysis_hplc_uv import definitions\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "from wine_analysis_hplc_uv.notebooks.dtw_methods import DTWNotebookMethods\n",
    "from wine_analysis_hplc_uv.signal_processing.mindex_signal_processing import (\n",
    "    SignalProcessor,\n",
    ")\n",
    "from pybaselines import Baseline\n",
    "import seaborn as sns\n",
    "sns.set_theme(rc={'figure.dpi': 100})\n",
    "import matplotlib.pyplot as plt\n",
    "from wine_analysis_hplc_uv.notebooks import eda_by_category_methods\n",
    "plotter = eda_by_category_methods.Plotting()\n",
    "\n",
    "scipro = SignalProcessor()\n",
    "\n",
    "data = pd.read_parquet(definitions.RAW_PARQ_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, no effect. The smoothing necessary to remove those detected peaks will result in unsatisfactory loss of signal information. Ergo better to use constraints in the peak detection algo. Also, remaining in simple long form with no multiindex massively reduces reshaping overhead and makes UDF functions much simpler to define..\n",
    "\n",
    "Now lets add kwargs for peak finder.. added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo process pipe with transform rather than apply\n",
    "\n",
    "# time std and drop vars level\n",
    "pdata = (\n",
    "    data.dropna()\n",
    "    .pipe(scipro.standardize_time)\n",
    "    .pipe(lambda df: df.set_axis(axis=0, labels=df.index.total_seconds() / 60))\n",
    "    .droplevel(\"vars\", axis=1)\n",
    ")\n",
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth\n",
    "from scipy import signal\n",
    "\n",
    "qdata = (\n",
    "    pdata.melt(ignore_index=False, value_name=\"signal\").reset_index()\n",
    "    # smooth signal with window length 5 and polynomial order 2\n",
    "    .assign(\n",
    "        smooth_signal=lambda df: df.groupby(\"samplecode\")[\"signal\"].transform(\n",
    "            func=signal.savgol_filter, **dict(window_length=5, polyorder=2)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "qdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bline\n",
    "\n",
    "\n",
    "def bline(x, y, i):\n",
    "    return pd.Series(Baseline(x, assume_sorted=True).asls(y)[0], index=i)\n",
    "\n",
    "\n",
    "rdata = qdata.assign(\n",
    "    bline=qdata.groupby(\"samplecode\")[\"smooth_signal\"].transform(\n",
    "        lambda x: Baseline(x.index).asls(x)[0]\n",
    "    )\n",
    ").eval(\"bcorr=smooth_signal-bline\")\n",
    "rdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "(\n",
    "    rdata.melt(\n",
    "        id_vars=[\"samplecode\", \"wine\", \"mins\"], var_name=\"siglabel\", value_name=\"sig\"\n",
    "    ).pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\", y=\"sig\", color=\"siglabel\")\n",
    "        .facet(col=\"samplecode\", wrap=2)\n",
    "        .add(mark=so.Line())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find peaks\n",
    "def peak_finder(x, kwargs: dict = dict()) -> pd.Series:\n",
    "    a = signal.find_peaks(x, **kwargs)[0]\n",
    "    peaks = x.iloc[a]\n",
    "    return peaks\n",
    "\n",
    "\n",
    "sdata = rdata.assign(\n",
    "    bcorr_peaks=lambda df: df.groupby(\"samplecode\")[\"bcorr\"].transform(peak_finder)\n",
    ")\n",
    "sdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to display peaks\n",
    "(\n",
    "    sdata.melt(\n",
    "        id_vars=[\"samplecode\", \"wine\", \"mins\"], var_name=\"siglabel\", value_name=\"sig\"\n",
    "    )\n",
    "    .loc[lambda df: (df.mins < 5) & (df.mins > 3)]\n",
    "    .pivot_table(index=[\"samplecode\", \"wine\", \"mins\"], columns=\"siglabel\", values=\"sig\")\n",
    "    .reset_index()\n",
    "    .pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\", color=\"samplecode\")\n",
    "        .add(so.Line(), y=\"bcorr\")\n",
    "        .add(so.Dot(), y=\"bcorr_peaks\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes, we're only interested in the top 10 peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 peaks per sample\n",
    "tdata = sdata.assign(\n",
    "    bcorr_top_10=lambda df: df.groupby(\"samplecode\", group_keys=False)[\n",
    "        \"bcorr_peaks\"\n",
    "    ].nlargest(10)\n",
    ")\n",
    "\n",
    "# plot the peaks on top of the curves\n",
    "display(\n",
    "    tdata.loc[lambda df: df.mins < 21].pipe(\n",
    "        lambda df: (\n",
    "            so.Plot(df, x=\"mins\", color=\"samplecode\")\n",
    "            .add(so.Line(), y=\"bcorr\")\n",
    "            .add(so.Dot(), y=\"bcorr_top_10\")\n",
    "            .plot()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# peak table\n",
    "(\n",
    "    tdata.pipe(\n",
    "        lambda df: (\n",
    "            df\n",
    "            if display(\n",
    "                df.loc[:, [\"samplecode\", \"wine\", \"mins\", \"bcorr_top_10\"]]\n",
    "                .dropna()\n",
    "                .assign(n_peak=lambda df: df.groupby(\"samplecode\").cumcount())\n",
    "                .pivot(\n",
    "                    columns=[\"samplecode\", \"wine\"],\n",
    "                    index=[\"n_peak\"],\n",
    "                    values=[\"mins\", \"bcorr_top_10\"],\n",
    "                )\n",
    "                .reorder_levels([1, 2, 0], axis=1)\n",
    "                .sort_index(axis=1)\n",
    "            )\n",
    "            else df\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now align, get the top 10 peaks after alignment and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dtw\n",
    "\n",
    "# find reference\n",
    "\n",
    "reference = (\n",
    "    tdata.pivot_table(columns=[\"samplecode\", \"wine\"], index=[\"mins\"], values=\"signal\")\n",
    "    .corr()\n",
    "    .mean()\n",
    "    .loc[lambda df: df == df.max()]\n",
    "    .pipe(lambda df: df if display(df) else df)  # display df\n",
    "    .index\n",
    ")\n",
    "\n",
    "display(reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: Use transform with a custom function if you are expecting a result with the same shape as the input i.e. a column of the dataframe. Apply rarely gets this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applydtw(query, ref, kwargs: dict = dict()):\n",
    "    \"\"\"\n",
    "    apply dtw\n",
    "    \"\"\"\n",
    "    # subset signal by warping path\n",
    "    # reset index to enable reindexing after Apply functions (i.e. transform), otherwise get duplicate index error\n",
    "    aligned_query = query.iloc[dtw(x=query, y=ref, **kwargs).get_warping_path()].reset_index(drop=True).values\n",
    "    \n",
    "    aligned_s = pd.Series(aligned_query, index=query.index)\n",
    "    \n",
    "    import pandas.testing as pt\n",
    "    def assert_series_not_equal(*args, **kwargs):\n",
    "        try:\n",
    "            pt.assert_series_equal(*args, **kwargs)\n",
    "        except AssertionError:\n",
    "            # frames are not equal\n",
    "            pass\n",
    "        else:\n",
    "            # frames are equal\n",
    "            raise AssertionError\n",
    "        return aligned_query\n",
    "    \n",
    "    assert_series_not_equal(left=query,right=aligned_s)\n",
    "    \n",
    "    return aligned_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_kwargs = dict(window_type=\"sakoechiba\", window_size=10)\n",
    "\n",
    "ref_signal = (\n",
    "    tdata.set_index([\"samplecode\", \"wine\"]).loc[reference].bcorr.reset_index(drop=True)\n",
    ")\n",
    "\n",
    "udata = tdata.assign(\n",
    "    align=lambda x: x.groupby([\"samplecode\"])[\"bcorr\"].transform(\n",
    "        applydtw, ref_signal, dtw_kwargs\n",
    "    )\n",
    ")\n",
    "\n",
    "udata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot alignment\n",
    "(\n",
    "    udata.pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\").add(\n",
    "            so.Line(), y=\"align\", color='samplecode'\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udata.set_index([\"samplecode\", \"wine\"]).loc[reference, \"bcorr\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torbreck-struie didnt align well. Try again?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Transform is a finnicky bitch. It requires that the output of UDFs are either pd.Series or pd.DataFrames, and that the output has the same index as the input. The reason for this is that it reindexes the output onto the source DF. You would expect it to handle that logic internally, but no, it does not.\n",
    "\n",
    "Also, avoid using multiindex as much as possible, it encourages practices which dont align with other OLAP engines such as SQL. Long over wide.\n",
    "\n",
    "Note: You can sub in 'display()' basically anywhere to display the target before an Exception is raised\n",
    "\"\"\"\n",
    "\n",
    "(\n",
    "    udata\n",
    "    # get torbreck-struie and the reference signal\n",
    "    .loc[\n",
    "        lambda df: (\n",
    "            (df.samplecode == \"torbreck-struie\")\n",
    "            | (df.samplecode == reference.get_level_values(\"samplecode\")[0])\n",
    "        )\n",
    "    ]\n",
    "    # add a column containing the warped path indices\n",
    "    .assign(\n",
    "        wp=lambda df: df.groupby('samplecode')[\"bcorr\"].transform(\n",
    "            lambda query: pd.Series(\n",
    "                dtw(\n",
    "                    x=query,\n",
    "                    y=df.set_index([\"samplecode\", \"wine\"])\n",
    "                    .loc[reference, \"bcorr\"]\n",
    "                    .reset_index(drop=True),\n",
    "                ).get_warping_path(),\n",
    "                index=query.index,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .reset_index(names=\"i\")\n",
    "    .assign(warped_signal=lambda df: df.bcorr.iloc[df.wp.values].reset_index(drop=True))\n",
    "    .set_index(\"i\")\n",
    "    # plot\n",
    "    .pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\").add(\n",
    "            so.Line(), y=\"align\", color='samplecode'\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
