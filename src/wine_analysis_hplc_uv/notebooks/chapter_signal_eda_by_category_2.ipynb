{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-10-18 Due to the fact that I am prototyping a lot of code and changing approaches (multiindex column default to long defaul primarily), literate progrmaming style is failing, re. version one of this notebook is somewhat unsalvagable - a testament to why rushing always fails in the end. At some point I'll have to go through and fix it. in the meantime, copy code over and push ON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dtwalign import dtw\n",
    "import pandas as pd\n",
    "from wine_analysis_hplc_uv import definitions\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "from wine_analysis_hplc_uv.notebooks.dtw_methods import DTWNotebookMethods\n",
    "from wine_analysis_hplc_uv.signal_processing.mindex_signal_processing import (\n",
    "    SignalProcessor,\n",
    ")\n",
    "from pybaselines import Baseline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wine_analysis_hplc_uv.notebooks import eda_by_category_methods\n",
    "plotter = eda_by_category_methods.Plotting()\n",
    "\n",
    "scipro = SignalProcessor()\n",
    "\n",
    "data = pd.read_parquet(definitions.RAW_PARQ_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, no effect. The smoothing necessary to remove those detected peaks will result in unsatisfactory loss of signal information. Ergo better to use constraints in the peak detection algo. Also, remaining in simple long form with no multiindex massively reduces reshaping overhead and makes UDF functions much simpler to define..\n",
    "\n",
    "Now lets add kwargs for peak finder.. added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time std and drop vars level\n",
    "\n",
    "pdata = (\n",
    "    data.dropna()\n",
    "    .pipe(scipro.standardize_time)\n",
    "    .pipe(lambda df: df.set_axis(axis=0, labels=df.index.total_seconds() / 60))\n",
    "    .droplevel(\"vars\", axis=1)\n",
    ")\n",
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth\n",
    "from scipy import signal\n",
    "\n",
    "qdata = (\n",
    "    pdata.melt(ignore_index=False, value_name=\"signal\").reset_index()\n",
    "    # smooth signal with window length 5 and polynomial order 2\n",
    "    .assign(\n",
    "        smooth_signal=lambda df: df.groupby(\"samplecode\")[\"signal\"].transform(\n",
    "            func=signal.savgol_filter, **dict(window_length=5, polyorder=2)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "qdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bline\n",
    "\n",
    "\n",
    "def bline(x, y, i):\n",
    "    return pd.Series(Baseline(x, assume_sorted=True).asls(y)[0], index=i)\n",
    "\n",
    "\n",
    "rdata = qdata.assign(\n",
    "    bline=qdata.groupby(\"samplecode\")[\"smooth_signal\"].transform(\n",
    "        lambda x: Baseline(x.index).asls(x)[0]\n",
    "    )\n",
    ").eval(\"bcorr=smooth_signal-bline\")\n",
    "rdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline correction\n",
    "\n",
    "(\n",
    "    rdata.melt(\n",
    "        id_vars=[\"samplecode\", \"wine\", \"mins\"], var_name=\"siglabel\", value_name=\"sig\"\n",
    "    ).pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\", y=\"sig\", color=\"siglabel\")\n",
    "        .facet(col=\"samplecode\", wrap=2)\n",
    "        .add(mark=so.Line())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "find peaks before alignment"
    ]
   },
   "outputs": [],
   "source": [
    "# detect peaks prior to alignment\n",
    "\n",
    "sdata = rdata.assign(\n",
    "    bcorr_peaks=lambda df: df.groupby(\"samplecode\")[\"bcorr\"].transform(lambda x: x.iloc[signal.find_peaks(x)[0]])\n",
    ")\n",
    "sdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to display peaks\n",
    "(\n",
    "    sdata.melt(\n",
    "        id_vars=[\"samplecode\", \"wine\", \"mins\"], var_name=\"siglabel\", value_name=\"sig\"\n",
    "    )\n",
    "    .loc[lambda df: (df.mins < 5) & (df.mins > 3)]\n",
    "    .pivot_table(index=[\"samplecode\", \"wine\", \"mins\"], columns=\"siglabel\", values=\"sig\")\n",
    "    .reset_index()\n",
    "    .pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\", color=\"samplecode\")\n",
    "        .add(so.Line(), y=\"bcorr\")\n",
    "        .add(so.Dot(), y=\"bcorr_peaks\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes, we're only interested in the top 10 peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 20 peaks of the unaligned set\n",
    "\n",
    "tdata = sdata.assign(\n",
    "    bcorr_top_20=lambda df: df.groupby(\"samplecode\", group_keys=False)[\n",
    "        \"bcorr_peaks\"\n",
    "    ].nlargest(20)\n",
    ")\n",
    "\n",
    "# plot the peaks on top of the curves\n",
    "display(\n",
    "    tdata.loc[lambda df: df.mins < 21].pipe(\n",
    "        lambda df: (\n",
    "            so.Plot(df, x=\"mins\", color=\"samplecode\")\n",
    "            .add(so.Line(), y=\"bcorr\")\n",
    "            .add(so.Dot(), y=\"bcorr_top_20\")\n",
    "            .plot()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# peak table\n",
    "(\n",
    "    tdata.pipe(\n",
    "        lambda df: (\n",
    "            df\n",
    "            if display(\n",
    "                df.loc[:, [\"samplecode\", \"wine\", \"mins\", \"bcorr_top_20\"]]\n",
    "                .dropna()\n",
    "                .assign(n_peak=lambda df: df.groupby(\"samplecode\").cumcount())\n",
    "                .pivot(\n",
    "                    columns=[\"samplecode\", \"wine\"],\n",
    "                    index=[\"n_peak\"],\n",
    "                    values=[\"mins\", \"bcorr_top_20\"],\n",
    "                )\n",
    "                .reorder_levels([1, 2, 0], axis=1)\n",
    "                .sort_index(axis=1)\n",
    "            )\n",
    "            else df\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now align, get the top 10 peaks after alignment and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: Use transform with a custom function if you are expecting a result with the same shape as the input i.e. a column of the dataframe. Apply rarely gets this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class to handle DTW methods\n",
    "\n",
    "class ApplyDTW():\n",
    "    \n",
    "    def align(self, data, primary_key, siglabel, aligned_label: str, kwargs:dict=dict()):\n",
    "        \"\"\"\n",
    "        For a passed long format df find the reference signal and align, assigning back\n",
    "        to the passed frame\n",
    "        \n",
    "        TODO: add internal validation\n",
    "        \"\"\"\n",
    "        \n",
    "        ref_idx = self.find_ref(data, primary_key, siglabel)\n",
    "        \n",
    "        \n",
    "        ref_signal = data.loc[lambda df: df.samplecode==ref_idx][siglabel]\n",
    "        \n",
    "        adata = (\n",
    "            data\n",
    "            .assign(**{aligned_label:data\n",
    "                       .groupby(primary_key)[siglabel]\n",
    "                       .transform(self.applydtw, ref_signal)\n",
    "                    }\n",
    "                       )\n",
    "                           )\n",
    "        \n",
    "        return adata\n",
    "        \n",
    "    \n",
    "    def applydtw(self, query, ref, kwargs: dict = dict()):\n",
    "        \n",
    "        \"\"\"\n",
    "        apply dtw\n",
    "        \"\"\"\n",
    "        # subset signal by warping path\n",
    "        # reset index to enable reindexing after Apply functions (i.e. transform), \n",
    "        # otherwise get duplicate index error\n",
    "        \n",
    "        aligned_query = (query.iloc[dtw(x=query, y=ref, **kwargs).get_warping_path()]\n",
    "        .reset_index(drop=True).values)\n",
    "        \n",
    "        aligned_s = pd.Series(aligned_query, index=query.index)\n",
    "        \n",
    "        return aligned_query\n",
    "    \n",
    "    def find_ref(self, data, primary_key:str, siglabel:str)->str:\n",
    "        \"\"\"\n",
    "        pass long form df and return the idx string for the reference sample\n",
    "        \"\"\"\n",
    "        \n",
    "        tidy_data = data.pivot_table(index='mins',columns=primary_key, values=siglabel)\n",
    "\n",
    "        \n",
    "        ref_idx = (\n",
    "            tidy_data\n",
    "            .corr()\n",
    "            .mean()\n",
    "            .loc[lambda df: df == df.max()]\n",
    "            .index[0]\n",
    "        )\n",
    "        return ref_idx\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref = ApplyDTW().find_ref(tdata, 'samplecode','bcorr')\n",
    "align = ApplyDTW().align(tdata, primary_key='samplecode',siglabel='bcorr', aligned_label='aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the dataset\n",
    "\n",
    "udata = dtwalignment(grouper=['samplecode','wine'], data=tdata, signal_label='bcorr', dtw_kwargs=dict(window_type='sakoechiba',window_size=500), ref_label=reference, aligned_signal_name='aligned_sig_1')\n",
    "udata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot aligned dataset\n",
    "\n",
    "(\n",
    "    udata\n",
    "    .loc[lambda df: df.mins<20]\n",
    "    .pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\",color='samplecode')\n",
    "        .layout(size=(5,3))\n",
    "        .add(\n",
    "            so.Line(), y=\"aligned_sig_1\"\n",
    "        )\n",
    "        \n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot aligned against unaligned set\n",
    "(\n",
    "    udata\n",
    "    .loc[lambda df: df.mins<20]\n",
    "    .melt(id_vars=['mins','samplecode','wine'],var_name='siglabel',value_vars=['bcorr','aligned_sig_1'],value_name='sig_val')\n",
    "    .pipe(\n",
    "        lambda df: so.Plot(data=df, x=\"mins\",color='siglabel')\n",
    "        .layout(size=(15,10))\n",
    "        .add(\n",
    "            so.Line(), y=\"sig_val\"\n",
    "        )\n",
    "        .facet(col='samplecode',wrap=2)\n",
    "    )\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect peaks in aligned set\n",
    "\n",
    "vdata = (udata\n",
    " .assign(\n",
    "    peaks_aligned=lambda df: df.groupby(\"samplecode\")[\"aligned_sig_1\"].transform(lambda x: x.iloc[signal.find_peaks(x)[0]])\n",
    ")\n",
    ")\n",
    "vdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column of top 20 peaks in aligned peak set\n",
    "\n",
    "wdata = vdata.assign(\n",
    "    aligned_top_20=lambda df: df.groupby(\"samplecode\", group_keys=False)[\n",
    "        \"peaks_aligned\"\n",
    "    ].nlargest(20)\n",
    ")\n",
    "wdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct and display peak table\n",
    "\n",
    "aligned_peak_table = (\n",
    "    wdata.pipe(\n",
    "        lambda df: \n",
    "                df\n",
    "                .loc[:,['mins','samplecode','wine','aligned_top_20']]\n",
    "                .dropna()\n",
    "                .assign(n_peak=lambda df: df.groupby(\"samplecode\").cumcount())\n",
    "                .pipe(lambda df: df if display(df) else df) # display df\n",
    "                .pivot_table(\n",
    "                    columns=[\"samplecode\", \"wine\"],\n",
    "                    index=[\"n_peak\"],\n",
    "                    values=[\"mins\", \"aligned_top_20\"],\n",
    "                )\n",
    "                .reorder_levels([1, 2, 0], axis=1)\n",
    "                .sort_index(axis=1)\n",
    "        )\n",
    "    )\n",
    "aligned_peak_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overlay signals and top 20 peaks\n",
    "\n",
    "(\n",
    "    wdata\n",
    "    .loc[lambda df: df.mins<20]\n",
    "    .pipe(lambda df:\n",
    "        so.Plot(df, x='mins', color='samplecode')\n",
    "        .add(so.Line(),y='aligned_sig_1')\n",
    "        .add(so.Dot(), y='aligned_top_20')\n",
    "        .facet(col='samplecode',wrap=2)\n",
    "        .layout(size=(15,10))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overlay aligned set, unaligned peaks, aligned peaks as dots\n",
    "\n",
    "plot_peak_data = wdata.melt(id_vars=['mins','samplecode','wine'],value_vars=['aligned_top_20','bcorr_top_20'], var_name='peak_label',value_name='sig').dropna()\n",
    "\n",
    "(\n",
    "    wdata\n",
    "    .loc[lambda df: df.mins<20]\n",
    "    .pipe(lambda df:\n",
    "        so.Plot(df, x='mins')\n",
    "        .add(so.Line(), y='aligned_sig_1',color='samplecode')\n",
    "        .add(so.Dot(),data=plot_peak_data.loc[lambda df: df.mins<20], alpha='peak_label', color='samplecode',x='mins',y='sig')\n",
    "        # .facet(col='samplecode',wrap=2)\n",
    "        .layout(size=(15,10))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above graphic, The majority of the peaks have lost amplitude, and torbreck-struie has straight up lost a peak at 18 mins. We need a better DTW algorithm.\n",
    "\n",
    "Need to develop a more reliable alignment method. But we also should look at whether torbreck-struie itself is the issue. First what happens if we exclude it during warping?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-analysis-hplc-uv-F-SbhWjO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
