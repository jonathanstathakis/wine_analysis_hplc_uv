---
bibliography: references.bib
---

Data Extraction Platform Planning

-   Outline Requirements

-   Outline Design

-   Introduction
    -   Need: Combine sample signal data with sampling and product metadata for modeling. One solution is a data warehouse.
    -   Data Warehouse
        -   A data warehouse is described by @song_2009 as "..an integrated repository of data put into a form that can be easily understood, interpreted, and analyzed.." and is an example of an OnLine Analytical Processing (OLAP) system used to produce insights about a dataset. A simple example of an OLAP system is Microsoft Excel.
    -   ETL pipeline
        -   An Extraction Transform Load (ETL) pipeline is a set of processes to collect data from multiple sources and collect them together in a standardized data structure such as a data warehouse [@snowflake_etl_pipeline_2023]
        -   Data warehouses are filled with data that traverses an ETL pipeline to clean and standardize it before storage [@reis_2022].
        -   Extraction
            -   Python
                -   Python is a commonly chosen development environment for ETL pipelines because it is free, well-documented, cross-platform, large volume of standard and third party libraries, large and active community. For data engineering and data science, `numpy`, `scikit-learn`, `matplotlib` and especially `pandas` are indispensible [@crickard2020].
                -   useful because most software has a Python API that enables it to act as an intermediary between entities such as storage locations.
                -   Enables automation of pipeline
            -   Agilent
                -   Agilent infinity stack controlled via Chemstation 3.05
                    -   single device software license.
                    -   proprietary practices that have failed to keep pace with the increasing size of laboratory groups, personalization of computation and fusion of data analysis tools such as ETL pipelines[@dÄ…browski_2015, pp. 193].
                    -   No batch export.
                        -   For 200 samples, Manual extraction would have required approximately 60 hours of work.
                        -   
                -   Rainbow
                    -   Search for chromatography software on Git Hub returns 286 results, ranging from converters to analysis platforms.
                    -   Rainbow, by @shi_2022 is a Python package for converting vendor-specific encrypted data into Python data structures during runtime with capability to output to Comma Separated Values (csv) files. This package was modified to expand the information extracted to include injection volumes, sequence names, original filepaths, and unique hash keys (to be used as identifiers).
            -   Sample Tracker
                -   Store sample specific information: date of bottle opening, name, origin of sample, detection method
                -   Chose Google Sheets
                    -   cloud based - cross platform accessible, version control, back ups
                    -   powerful Python API for automation of pipeline integration
                    -   [here](https://docs.google.com/spreadsheets/d/15S2wm8t6ol2MRwTzgKTjlTcUgaStNlA22wJmFYhcwAY/edit#gid=347137817)
            -   Cellar Tracker
                -   wine metadata such as full names, vintages, varietals, growing regions, producers etc.
                -   [Cellar Tracker](https://www.cellartracker.com/)
                -   Free access to metadata of all wines in database
                -   `cellartracker` by @rul2020 provides a Python API for Cellar Tracker to automate extraction of metadata
        -   Transformation
            -   `pandas` is a free and open-source data analysis package written in Python intended for work with labeled, tabular data [@mckinney2022] such as chromatographic signals. It can be used to provide insights during prototyping, transformation and sanitation, and interface with downstream processes. It is so ubiquitous that most data-focused Python libraries allow direct use of `pandas` `DataFrame` objects.
            -   cleaning data
                -   reduce strings to lower case, remove white space and illegal characters, rename columns where necessary.
            -   Join Keys
                -   Description
                    -   Relational Databases join tables on columns designated as join keys. In good design practice, each table contains a primary key which is a unique identifier for each row in the table, and *n* foreign key columns which are the unique identifiers of a table to join at a future date. Sometimes, the primary key can also be the foreign key. Also, multiple columns can be concatenated together to form a primary key so long as the resulting value is unique.
                    - Creating correct key columns can be difficult in and automated project and requires validation.
              - Implementation
                -   Chemstation Metadata and Chemstation Chromatogram Spectra shared a 'hash_key' generated by Agilent at the time of sampling, extracted from stored metadata.
                -   Chemstation Metadata and Sample Tracker shared a 'sample_id' created by the Experimentalist at the time of sampling and entered into Chemstation as the sample name.
                -   Sample Tracker and Cellar Tracker shared a 'wine_name' the name of the wine according to Cellar Tracker. To standardize the wine names between Sample Tracker (which was user input) and Cellar Tracker, a fuzzy search algorithm was used, any matches less than a threshold criteria were manually validated or edited to match.
        -   Loading
            -   As a data warehouse is an abstract concept, it can be created in many mediums. A popular approach is to use SQL Relational DataBase Management System (RDBMS).
                -   DuckDB [@raasveldt_2019, @raasveldt_2019a] is one such SQL OLAP RDBMS [@anand2022].
                -   Advantages of DuckDB include:
                    -   shares syntax with SQLite, MySQL, and PostgreSQL, three of the most popular SQL databases today.
                    -   optimized for analytical research
                    -   internal input and output of pandas dataframes.
                -   Design
                    -   Four tables
                        -   Chemstation Metadata
                        -   Chemstation Chromatogram Spectra.
                            - To reduce duplication of data values, a normalized design was followed [@tanimura, pp. 14]. 
                            - a long format table made up of horizontally stacked spectra matrices was found to be the most efficient approach
                            - enabled subsetting of the chromatogram-spectra space without having to load all signals first.
                        -   Sample Tracker
                        -   Cellar Tracker
        -   Use
            -   Repository of the Pipeline can be found here: @jstathakis_2023
            -   Direct queries could be made through the DuckDB CLI program.
            -   Automation of complex or repeated queries were written as Python modules.
            -   An example of a query enabled by this data warehouse approach is 'return red wines from Australia, 2021 vintage, detected under CUPRAC, 450nm wavelength, 15 - 20 mins'.
            -   