{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Dataset Thus Far\n",
    "\n",
    "see [2023-04-05_logbook](/Users/jonathan/001_obsidian_vault/mres_logbook/2023-04-05_logbook.md) for task description."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from agilette.modules.library import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = \"/Users/jonathan/0_jono_data/\"\n",
    "\n",
    "lib = Library(runs)\n",
    "\n",
    "df = lib.metadata_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acq_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['acq_date']>pd.to_datetime('2023-01-01', format = '%Y-%m-%d')].describe(datetime_is_numeric=True, include='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the dataset for 2023 extends from 2023-01-23 to 2023-04-05. What are the major separations? Halo to Avantor is the primary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Halo and Avantor Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up string columns. For some reason using the pandas string test replaces the posix paths with NaN. Workaround is to drop it from the df then apply on those remaining.\n",
    "df[df.columns.drop('path')] = df[df.columns.drop('path')].apply(lambda x : x.str.lower() if pd.api.types.is_string_dtype(x) else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avantor Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_df = df[(df['acq_date'] > '2023-01-01') & (df['acq_method'].str.contains('avantor'))]\n",
    "avantor_df.describe(datetime_is_numeric=True, include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeline of All Runs with Sequences as Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def library_timeline(df = pd.DataFrame) -> go.Figure:\n",
    "    f = go.Figure()\n",
    "\n",
    "    df = df.fillna('None')\n",
    "\n",
    "    library_trace = go.Scatter(x = df['acq_date'], y = df['id'], mode = 'markers+text', text=df['id'], textposition='top right')\n",
    "\n",
    "    f.add_trace(library_trace)\n",
    "\n",
    "    sequences_start_finish_times = df[df['program_type']=='sequence'].groupby('sequence_name').agg({'acq_date':['min','max']})\n",
    "\n",
    "    sequences_start_finish_times.apply(lambda row : f.add_shape(x0 = row[('acq_date', 'min')], x1= row[('acq_date', 'max')], y0 = 0, y1=120), axis =1)\n",
    "\n",
    "    return f\n",
    "\n",
    "f = library_timeline(avantor_df)\n",
    "f.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 197 avantor runs running from 2023-02-07 to 2023-04-05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halo Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo_df = df[(df['acq_date'] > '2023-01-01') & (df['acq_method'].str.contains('halo'))]\n",
    "halo_df.describe(datetime_is_numeric=True, include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesnt seem right, but it doesnt matter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Avantor Single Runs and Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_df.groupby('program_type').describe(datetime_is_numeric=True, include = 'all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far there have been 165 runs as sequences, and 32 as single runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avantor Single Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_runs = avantor_df[avantor_df['program_type']=='single run']\n",
    "single_runs.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avantor Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups = avantor_df[avantor_df.program_type=='sequence'].groupby('sequence_name')\n",
    "avantor_sequence_groups.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the sequences with size of 1 can be declared to be defunct, or deletable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing 1 Run Sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which ones only have 1 run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups.filter(lambda x: len(x) == 1).groupby('sequence_name').groups.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The failed Uracil runs and two runs from mid March with the shifting baseline problem. Can drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups = avantor_sequence_groups.filter(lambda x: len(x) > 1).groupby('sequence_name')\n",
    "avantor_sequence_groups.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Two Run Seqeuence '2023-03-24_wines_2023-03-24_13-17-09'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what about that sequence with 2 runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups.filter(lambda x: len(x) == 2).groupby('sequence_name').head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks legit. Keep it in the dataset.\n",
    "\n",
    "So number of sequences is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups.size().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping 44min runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of my dataset is on a 52 minute gradient run. I hypothesize that 52 min run chromatograms should be compatible with 44min runs, but I haven't proven this yet. In the meantime, I would like to eliminate 44min runs from the dataset IF they do not contain uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups.get_group('2023-03-16_red-wines-44min_2023-03-16_12-08-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_groups_44min_2023_03_16 = avantor_df.loc[avantor_df['id'].isin(avantor_sequence_groups.get_group('2023-03-16_red-wines-44min_2023-03-16_12-08-23')['id'])].groupby(['id','sequence_name'])\n",
    "\n",
    "size = id_groups_44min_2023_03_16.size()\n",
    "size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, it appears that '2023-03-16_red-wines-44min_2023-03-16_12-08-23' is a repeat, and that all those wines were included in \"2023-03-14_wines_2023-03-14_19-49-27\" and \"2023-03-15_wine_dups_2023-03-15_22-17-47\". Should drop these two repeat sequences and continue.\n",
    "\n",
    "After this, it would be a good idea to make a brief summary of each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avantor_sequence_groups.size().index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "There are two duplicate runs that I know of:\n",
    "- '2023-03-15_wine_dups_2023-03-15_22-17-47'\n",
    "- '2023-03-16_random_wines_repeat_44min_run_2023-03-16_17-30-55'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Sequence Cleanup to `Avantor_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sequences with only 1 run, duplicates, 44 min runs, and acetone runs. \n",
    "\n",
    "avantor_sequence_groups = avantor_df.groupby('sequence_name')\n",
    "\n",
    "sequences_to_drop = list(avantor_sequence_groups.filter(lambda x: len(x) == 1).groupby('sequence_name').groups.keys())+ avantor_df[avantor_df['sequence_name'].str.contains('dups')]['sequence_name'].unique().tolist() + avantor_df[avantor_df['sequence_name'].str.contains('repeat')]['sequence_name'].unique().tolist() + avantor_df[avantor_df['sequence_name'].str.contains('44min')]['sequence_name'].unique().tolist() + avantor_df[avantor_df['sequence_name'].str.contains('acetone')]['sequence_name'].unique().tolist()\n",
    "\n",
    "print(sequences_to_drop)\n",
    "\n",
    "avantor_df = avantor_df[avantor_df['sequence_name'].isin(sequences_to_drop)==False]\n",
    "\n",
    "# drop single runs.\n",
    "\n",
    "avantor_df = avantor_df[avantor_df.program_type == 'sequence']\n",
    "\n",
    "avantor_df.groupby('sequence_name').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avantor_df['id'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So according to my defined criteria, there are 78 unique wines sampled and appropriate for further analysis. Let's show the timeline again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = library_timeline(avantor_df)\n",
    "f2.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Wines Thus Far."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a better idea of the timeline, I need to start looking at what my samples actually are. Three questions:\n",
    "\n",
    "1. Group samples by variety.\n",
    "2. Number of sample repeats.\n",
    "3. Of sample repeats, how many repeats, over what lengths of time?\n",
    "\n",
    "To do this, I will need to join the metadata table with tracker table, but I will also need to join the tracker table with a cellartracker metadata table. Lots of work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
