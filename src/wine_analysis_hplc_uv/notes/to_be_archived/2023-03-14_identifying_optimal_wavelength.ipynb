{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Optimal Wavelength of Study of my Wine Library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leading in from [Investigating Shortening Runtimes]('2023-03-14_investigating-shortening-runtimes.ipynb').\n",
    "\n",
    "The question of which wavelength is optimal, that is, which wavelength contains the most information, has been coming for a while. Rather than setting my instrument trace to a range of wavelengths and bloating my data dir size,  I can just pull the spectrum and that one optimal wavelength. But how do you define 'optimal', or 'most information'? I will use the definition of minimal average baseline gradient to maximal average peak heights. That is, any variation in peaks should be sample specific and not random background noise or intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pybaselines import Baseline\n",
    "\n",
    "# adds root dir 'wine_analyis_hplc_uv' to path.\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "\n",
    "from agilette import agilette_core as ag\n",
    "\n",
    "lib = ag.Agilette(\"/Users/jonathan/0_jono_data\").library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_df = lib.data_table()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the leading in notebook, I will use the latest De Bertoli Cab Merlot sample `2023-03-07_DEBERTOLI_CS_001.D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = lib.single_runs[lib_df.loc[3].run_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.load_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.spectrum.line_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further, for these calculations, it is necessary to scale all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_df = scaler.fit_transform(run.spectrum.uv_data.values)\n",
    "\n",
    "scaled_uv_data = pd.DataFrame(\n",
    "    scaled_df, columns=run.spectrum.uv_data.columns, index=run.spectrum.uv_data.index\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Average Baseline Gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First fit the baseline for each wavelength of the spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_calculator(column):\n",
    "    baseline_fitter = Baseline(column.index)\n",
    "    baseline_y = baseline_fitter.iasls(column.values)\n",
    "\n",
    "    return baseline_y[0]\n",
    "\n",
    "\n",
    "scaled_uv_data = scaled_uv_data.set_index(\"mins\")\n",
    "\n",
    "baselines = scaled_uv_data.apply(baseline_calculator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average Gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of what we are trying to achieve, let's plot the 254nm wavelength chromatogram with its fitted baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_254 = baselines[\"254\"]\n",
    "\n",
    "fig_1 = go.Figure()\n",
    "\n",
    "chrom_trace = go.Scatter(\n",
    "    x=scaled_uv_data[\"254\"].index.values, y=scaled_uv_data[\"254\"].values, name=\"chrom\"\n",
    ")\n",
    "\n",
    "baseline_trace = go.Scatter(x=baseline_254.index, y=baseline_254, name=\"baseline\")\n",
    "fig_1.add_trace(chrom_trace)\n",
    "\n",
    "fig_1.add_trace(baseline_trace)\n",
    "\n",
    "fig_1.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the average gradient we can simply use `np.gradient()` which returns a numpy array, then take the mean of that array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_av_grad(column):\n",
    "    grad = np.gradient(column)\n",
    "    return np.mean(grad)\n",
    "\n",
    "\n",
    "av_baseline_grad = baselines.apply(calc_av_grad)\n",
    "\n",
    "av_baseline_grad.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as expected, the further you get from the Methanol cuttoff, the lower the average baseline fluctuation.\n",
    "\n",
    "The average baseline is now calculated, onto average peak height."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Peak Maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_correction(column):\n",
    "    baseline_fitter = Baseline(x_data=column.index.values)\n",
    "    baseline_y = baseline_fitter.iasls(column.values)[0]\n",
    "\n",
    "    corrected_column = column - baseline_y\n",
    "    return corrected_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_corrected_data = scaled_uv_data.apply(baseline_correction)\n",
    "\n",
    "baseline_corrected_data[190].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Peak Height Values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the peak height values, we can use `scipy.signal.find_peaks`. A height of 4 will be the minimum requirement, and all other settings will be the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_finder(column):\n",
    "    peaks = find_peaks(height=0.05, x=column)\n",
    "\n",
    "    # peaks[0] is the peak maxima indexes.\n",
    "\n",
    "    peaks_x = column.index[peaks[0]]\n",
    "\n",
    "    # peak[1] is a dict with information about the peaks including peak heights.\n",
    "    peaks_y = peaks[1][\"peak_heights\"]\n",
    "    return peaks_x, peaks_y\n",
    "\n",
    "\n",
    "found_peaks = baseline_corrected_data.apply(peak_finder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the peak finder algorithm worked as expected, let's plot the peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_finder_190_fig = go.Figure()\n",
    "\n",
    "chromatogram_trace_190 = go.Scatter(\n",
    "    x=baseline_corrected_data[190].index,\n",
    "    y=baseline_corrected_data[190].values,\n",
    "    name=\"190 nm\",\n",
    "    mode=\"lines\",\n",
    ")\n",
    "\n",
    "peak_trace = go.Scatter(\n",
    "    x=found_peaks[190][0], y=found_peaks[190][1], name=\"peaks\", mode=\"markers\"\n",
    ")\n",
    "\n",
    "peak_finder_190_fig.add_traces([chromatogram_trace_190, peak_trace])\n",
    "\n",
    "peak_finder_190_fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to calculate the average peak height for each wavelength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_av_calc(column):\n",
    "    return column[1].mean()\n",
    "\n",
    "\n",
    "av_peak_height = found_peaks.apply(peak_av_calc)\n",
    "av_peak_height.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the average peak heights and average baseline gradient, just need to find the wavelength with the highest ratio of peak_height : baseline gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_height_baseline_grad_ratio = av_peak_height / av_baseline_grad\n",
    "peak_height_baseline_grad_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"av heights\": av_peak_height,\n",
    "        \"av_baseline_grad\": av_baseline_grad,\n",
    "        \"ratio\": peak_height_baseline_grad_ratio,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_peaks_extractor(column):\n",
    "    return len(column[1])\n",
    "\n",
    "\n",
    "number_of_peaks_per_nm = found_peaks.apply(found_peaks_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_names = list(result_df.columns)\n",
    "\n",
    "subplot_names.append(\"\")\n",
    "\n",
    "subplot_names.append(\"# peaks per nm\")\n",
    "\n",
    "fig = make_subplots(rows=2, cols=3, subplot_titles=subplot_names)\n",
    "\n",
    "print(result_df.columns)\n",
    "\n",
    "for idx, column in enumerate(result_df.columns):\n",
    "    print(idx, column)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=result_df.index, y=result_df[column], mode=\"lines\", name=column),\n",
    "        row=1,\n",
    "        col=idx + 1,\n",
    "    )\n",
    "    fig.update_layout(title=run.name, showlegend=False)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=number_of_peaks_per_nm.index, y=number_of_peaks_per_nm.values),\n",
    "    row=2,\n",
    "    col=2,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting result. 262 appears to be the best for these current settings, but I get the feeling that my peak detection needs more nuance. My current process is:\n",
    "\n",
    "1. MinMax scale the whole data set.\n",
    "2. Calculate baseline.\n",
    "3. Calculate average baseline gradient.\n",
    "3. Subtract baseline from signals.\n",
    "4. Calculate average peak height.\n",
    "5. Calculate ratio.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will continue this line of investigation in [investigating-optimal-wavelength-for-all-runs](2023-03-15_investigating-optimal-wavelength-for-all-runs.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
