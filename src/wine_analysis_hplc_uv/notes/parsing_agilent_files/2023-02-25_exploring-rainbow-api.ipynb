{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2438d290-fbc9-4410-bf52-dc2da15ec433",
   "metadata": {},
   "source": [
    "# Exploring Rainbow API for use in Data class structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68022c0e-376c-4a7b-b25a-b03bb9c49fa9",
   "metadata": {},
   "source": [
    "There are a few things I want to investigate:\n",
    "\n",
    "- [x] passing the .UV data directly to other Python objects without exporting to `.csv` first.\n",
    "- [x] What run metadata is available.\n",
    "\n",
    "Once these are clarified we can explore how to best intregrate rainbow-api objects into my Data class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ea62e-68c5-476d-a11b-33f31aa90c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rainbow as rb\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "p = \"/Users/jonathan/0_jono_data/2023-02-07_18-30-07_Z3-ID-NM-ABS-MAX.D\"\n",
    "\n",
    "data = rb.read(str(p))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7f6b1-ea96-43be-ae82-988f20085869",
   "metadata": {},
   "source": [
    "So the DataDirectory objects contain:\n",
    "\n",
    "- DataDirectory.name - name of the data directory .D.\n",
    "- DataDirectory.datafiles -  a list of all the data files.\n",
    "- DataDirectory.metadata - a dict of metadata including run date time and vial position.\n",
    "- DataDirectory.get_info() outputs a text string with ALL the information and data. Method name can be gotten from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed129f-a77a-4be5-b219-48b60d7f7537",
   "metadata": {},
   "source": [
    "Regarding the method data, based on the source code for `parse_uv()`, I should expect to be able to access the method name, however the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9ecb9-e915-4355-9de1-20583fd6fde3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e386a-2dfa-4c3b-a4ef-1912a1ec5548",
   "metadata": {},
   "source": [
    "does not contain the method name. Maybe try accessing the metadata specific to a .ch or .uv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c69a36-a6e4-48c7-9d7b-da29032abbda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = \"/Users/jonathan/0_jono_data/2023-02-07_18-30-07_Z3-ID-NM-ABS-MAX.D\"\n",
    "\n",
    "data = rb.read(str(p))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9a12d-410b-41bc-b584-91c2b5af5790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.get_file(\"DAD1A.ch\").metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1d6d3-314f-4968-ac26-fc417290dc87",
   "metadata": {},
   "source": [
    "So the method names are contained in the metadata of the individual signals. That's fine. We've essentially got the desired class heirarchy provided by rainbow then."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c1a13-ca71-4cd4-96c7-edf6aeb5472c",
   "metadata": {},
   "source": [
    "It would be useful to produe a table of all data within a given top-level directory, then access those files with rainbow to extract the desired queries, then return as tables, i.e.\n",
    "\n",
    "```\n",
    "with 0_jono_data as dir:\n",
    "\n",
    "data_table = table(dir)\n",
    "\n",
    "print(data_table(sample name, acq time, method, signals contained, run time..))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2131f7-b0f0-4e74-8526-390c09b03442",
   "metadata": {},
   "source": [
    "So lets try and action that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08cea5-a634-490c-b169-d910197bd2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_dir = Path(\"/Users/jonathan/0_jono_data\")\n",
    "\n",
    "for obj in top_dir.iterdir():\n",
    "    if obj.name.endswith(\".D\"):\n",
    "        print(obj.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83460883-32c0-42ac-abb2-1336f368dec2",
   "metadata": {},
   "source": [
    "Build it as a DF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a28db5-e58a-4b69-9c2c-75dc32849e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_dir_d = {}\n",
    "\n",
    "for obj in top_dir.iterdir():\n",
    "    if obj.name.endswith(\".D\"):\n",
    "        try:\n",
    "            top_dir_d[obj.name] = rb.read(str(obj))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c71318-c2a4-46ed-a1eb-2cab0a86f883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def acq_method(data_directory):\n",
    "    return data_directory.datafiles[0].metadata[\"method\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cd317-adb3-4934-b42d-8c6f99d32b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime_obj = datetime.strptime(data.metadata[\"date\"], \"%d-%b-%y, %H:%M:%S\")\n",
    "\n",
    "top_dir_d = {}\n",
    "\n",
    "top_dir_d[\"name\"] = []\n",
    "top_dir_d[\"data\"] = []\n",
    "top_dir_d[\"num_detect_files\"] = []\n",
    "top_dir_d[\"method\"] = []\n",
    "top_dir_d[\"acquisition_date\"] = []\n",
    "\n",
    "for obj in top_dir.iterdir():\n",
    "    if obj.name.endswith(\".D\"):\n",
    "        try:\n",
    "            data = rb.read(str(obj))\n",
    "\n",
    "            top_dir_d[\"name\"].append(\"_\".join(obj.name.split(\"_\")[1:]))\n",
    "            top_dir_d[\"data\"].append(data)\n",
    "            top_dir_d[\"num_detect_files\"].append(len(data.datafiles))\n",
    "            top_dir_d[\"method\"].append(acq_method(data))\n",
    "            top_dir_d[\"acquisition_date\"].append(\n",
    "                datetime.strptime(data.metadata[\"date\"], \"%d-%b-%y, %H:%M:%S\")\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(obj.name, e)\n",
    "\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d8394-5a0f-4c19-a593-2685f3288d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(top_dir_d, index=top_dir_d[\"name\"])\n",
    "\n",
    "df = df.set_index(\"name\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab3541-fda0-4b4c-bdd2-ff4247fc24ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = df.drop('name', axis = 1)\n",
    "\n",
    "zeroth_col = list(df.columns).index(\"acquisition_date\")\n",
    "second_col = list(df.columns).index(\"method\")\n",
    "third_col = list(df.columns).index(\"num_detect_files\")\n",
    "fourth_col = list(df.columns).index(\"data\")\n",
    "try:\n",
    "    print(\"hi\")\n",
    "\n",
    "    print(df.shape)\n",
    "\n",
    "    df = df.iloc[:, [zeroth_col, second_col, third_col, fourth_col]]\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df = df.sort_values(by=\"acquisition_date\", ascending=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bdd1e-656e-4a53-a2e0-99e087c382db",
   "metadata": {
    "tags": []
   },
   "source": [
    "DF is looking good. Now how about data access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105d6c4-71ab-4af2-9e6c-f9f1965e3425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datadir = df.loc[\"STONEY-RISE-PN_02-21.D\"][\"data\"]\n",
    "\n",
    "data_uv = datadir.get_file(\"DAD1.UV\")\n",
    "\n",
    "traces = data_uv.extract_traces()\n",
    "\n",
    "\n",
    "traces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0c2da-9790-483d-9bd9-766e7ffd88c5",
   "metadata": {},
   "source": [
    "Where is the time axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95922436-dcf8-49d8-9e71-37b63b7dea8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916db0c-f525-4bdd-acb0-5462a4b49e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(data_uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d46c7-11eb-42ef-a0d1-5bc042434b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xlabeldf = pd.DataFrame(data_uv.xlabels)\n",
    "xlabeldf.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb69535-3e02-47a1-b6df-96fb626b91a4",
   "metadata": {},
   "source": [
    "So it looks like the time is stored in the xlabels member object of the DataFile class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eec411-6983-445f-9474-c17d9b9fb4bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "So we currently have a 2d plane for the detector and a 2 1D vectors of time and wavelengths corresponding to the axes. First off, is it possible to parse a 2d numpy array in pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e032fd-8964-4d88-b465-a75ed954a1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = data_uv.extract_traces().transpose()\n",
    "\n",
    "    print(data.shape)\n",
    "\n",
    "    test_df = pd.DataFrame(data=data, index=data_uv.xlabels, columns=data_uv.ylabels)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa790c-cf69-42c7-9c2e-7418dbf9e9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072a791-b343-41fa-92f9-a9497f06370b",
   "metadata": {},
   "source": [
    "yes. done. Now we've got some basic functionality we should rebuild these as modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f5088-1029-48da-96d9-cb749ad6997a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
