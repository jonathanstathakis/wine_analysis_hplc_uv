{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Adding Sequences to the Data Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "As per 2023-03-02_logbook.md I want to both add data files contained in sequence directories to the main data table when that is constructed AND add a column to the data table denoting which sequence the data came from, or \"single run\" if the data was obtained outside of a sequence.\n",
    "\n",
    "It is tasks such as this which big for an OOP approach to handlnig the data, but that is still a little bit away as I'm not 100% on Python OOP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "First let's generate the data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import rainbow as rb\n",
    "\n",
    "\n",
    "from scripts.core_scripts.data_interface import retrieve_uv_data\n",
    "\n",
    "from scripts.core_scripts.data_interface import data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = Path(\"/Users/jonathan/0_jono_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "First gen the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_table(p).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datadir_p = Path(\n",
    "    \"/Users/jonathan/0_jono_data/2023-02-23_2021-DEBORTOLI-CABERNET-MERLOT_AVANTOR.D\"\n",
    ")\n",
    "\n",
    "datadir = rb.read(str(datadir_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datadir.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "There doesnt seem to be a way to get the sample name specifically, so we should instead pull the sample name from the `SAMPLE.XML` field `<Name>`. At the same time we can pull the `<Description>` as well. Now, how to manipulate XML files in Python?\n",
    "\n",
    "## Working with XML files in Python\n",
    "\n",
    "### Getting Set Up\n",
    "\n",
    "According to [this article](https://www.geeksforgeeks.org/reading-and-writing-xml-files-in-python/) BeautifulSoup and Elementtree can both be used to Parse XML files. ~~I think Elementtree is what the rainbow-api devs used~~ *Actually, they use etree from lxml*, however, BeautifulSoup is ubiquitous in the greater world, so I will use that.\n",
    "\n",
    "### Parsing an XML File\n",
    "\n",
    "When parsing an XML file, you first find a *tag* then extract from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(datadir_p / r\"SAMPLE.XML\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "We've established that we can read the data. Now to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Bs_data = BeautifulSoup(data, \"xml\")\n",
    "Bs_data.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_unique = Bs_data.find_all(\"unique\")\n",
    "\n",
    "b_name = Bs_data.find(\"Sample\")\n",
    "\n",
    "print(b_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Problem - due to the way its encoded, I don't think BeautifulSoup is parsing it correctly. According to [this stackoverflow post](https://stackoverflow.com/questions/17534932/how-to-verify-xml-encoding) I can check the encoding by reading the first eight bytes of the file. I can either do that with a HEX editor or through Python directly with the 'b' argument in `read()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(datadir_p / r\"SAMPLE.XML\", \"rb\") as f:\n",
    "    data = f.read(8)\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Doesn't provide what I was expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "On another tack, looking at the rainbow code [here](https://github.com/evanyeyeye/rainbow/blob/main/rainbow/agilent/chemstation.py), I can see that it does parse the xml files, but it appears to be looking for a AcqData directory which is not present in my data files. Perhaps Agilent changed how the files are structured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Pivoting back to the XML problem, inspecting the files in the terminal with bat showed that the `SAMPLE.XML` file is encoded with UTF-16LE. Maybe try that as a setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(datadir_p / r\"SAMPLE.XML\", \"r\", encoding=\"UTF-16LE\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "That seems happier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Bs_data = BeautifulSoup(data, \"xml\")\n",
    "print(Bs_data.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Yes, that's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_sample = Bs_data.find(\"Sample\")\n",
    "\n",
    "print(b_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "And to access the name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = b_sample.find(\"Name\")\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Ok, but how do I get that out as a string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "try `str()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "That doesn't work. What about [soup's documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)? It mentions a `get_text()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_str = name.get_text()\n",
    "name_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(name_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "And there we go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## OOP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Fuck it, let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\"\"\"\n",
    "a prototyped class definition using bits of rainbow and bits of direct XML parsing.\n",
    "\n",
    "I'll keep building it from here as my use case increases, but it is barebones atm.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.name = self.load_meta_data()[0]\n",
    "        self.description = self.load_meta_data()[1]\n",
    "        self.rainbow = self.rb_object()\n",
    "        self.uv_data = retrieve_uv_data(rb.read(str(self.file_path)))\n",
    "        self.method = self.rainbow.datafiles[0].metadata[\"method\"]\n",
    "        self.acq_date = datetime.strptime(\n",
    "            self.rainbow.metadata[\"date\"], \"%d-%b-%y, %H:%M:%S\"\n",
    "        )\n",
    "        self.sequence_name = self.sequence_name()\n",
    "\n",
    "    def sequence_name(self):\n",
    "        if \".sequence\" in self.file_path.parent.name:\n",
    "            return self.file_path.parent.name\n",
    "        else:\n",
    "            return \"single run\"\n",
    "\n",
    "    def load_meta_data(self):\n",
    "        \"\"\"\n",
    "        atm this loads the name and description from SAMPLE.XML found in .D dirs.\n",
    "        It also cleans the description string.\n",
    "\n",
    "        Atm it needs to load the whole XML file to read these two tags, which seems inefficient\n",
    "        but i dont know how to do it otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.file_path / r\"SAMPLE.XML\", \"r\", encoding=\"UTF-16LE\") as f:\n",
    "            xml_data = f.read()\n",
    "\n",
    "            bsoup_xml = BeautifulSoup(xml_data, \"xml\")\n",
    "\n",
    "            name = bsoup_xml.find(\"Name\").get_text()\n",
    "\n",
    "            description = bsoup_xml.find(\"Description\").get_text()\n",
    "            clean_description = description.replace(\"\\n\", \"\").replace(\" \", \"-\").strip()\n",
    "\n",
    "        return name, clean_description\n",
    "\n",
    "    def rb_object(self):\n",
    "        \"\"\"\n",
    "        loads the whole target data dir, currently it just returns the method and the data.\n",
    "        \"\"\"\n",
    "        rainbow_obj = rb.read(str(self.file_path))\n",
    "\n",
    "        return rainbow_obj\n",
    "\n",
    "\n",
    "a_data_file = Data(datadir_p)\n",
    "\n",
    "print(a_data_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_data_file.sequence_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_data_file = Data(\n",
    "    Path(\n",
    "        \"/Users/jonathan/0_jono_data/2023-02-16_WINES_2023-02-16_13-46-32.sequence/001-0101.D\"\n",
    "    )\n",
    ")\n",
    "seq_data_file.sequence_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_data_file.method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_data_file.uv_data[350].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str(a_data_file.acq_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Now, a top level data dir class could be useful..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It will be able to return individual data files, all the single runs, and all the sequences.\n",
    "\n",
    "\n",
    "class Top_Dir:\n",
    "    def __init__(self, dir_path):\n",
    "        self.path = dir_path\n",
    "        self.single_runs = self.single_runs()\n",
    "        self.sequences = self.sequences()\n",
    "\n",
    "    def single_runs(self):\n",
    "        single_run_list = []\n",
    "\n",
    "        for obj in self.path.iterdir():\n",
    "            if obj.name.endswith(\".D\"):\n",
    "                try:\n",
    "                    single_run_list.append(obj.name)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"{e}\")\n",
    "\n",
    "    def sequences(self):\n",
    "        single_run_list = []\n",
    "\n",
    "        for obj in self.path.iterdir():\n",
    "            if obj.name.endswith(\".sequence\"):\n",
    "                try:\n",
    "                    single_run_list.append(obj.name)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"{e}\")\n",
    "\n",
    "        return single_run_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_dir = Top_Dir(p)\n",
    "\n",
    "top_dir.sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "I don't know yet how to handle the sequence data files. Whatever container I use for the data should simply 'unwrap' the sequence directories and store the single run and sequence .D at the same level, keeping track of the origin of the file - \"sequence\" or \"single run\".\n",
    "\n",
    "The answer is to build a class heirarchy corresponding to the file structure. Lets call the application Agilette, a petit Agilent Chemstation imitator.\n",
    "\n",
    "Agilette\n",
    " |  |\n",
    " |  |___top_dir\n",
    " |              |\n",
    " |              |__**sequences*\n",
    " |              |\n",
    " |              |__*single_runs*\n",
    " |\n",
    " |__data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agilette:\n",
    "    def __init__(self, path=str):\n",
    "        self.path = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag = Agilette(\"/Users/jonathan/0_jono_data/\")\n",
    "ag.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "tags": []
   },
   "source": [
    "I've reached a point where I should be refactoring this all into .py files. Ill do that now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
