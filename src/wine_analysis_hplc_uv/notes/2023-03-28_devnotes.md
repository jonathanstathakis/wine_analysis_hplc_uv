It would be useful at this point to tidy up Agilette and add baseline, peak, and correction functions to that codebase. I should also scour my logbook to make any other corrections. Best way to do that would be to form a table of notes sorted by date with the contents of each note and a uri link to the note. That should be done in a seperate notebook tho.

I currently have an elaborate function called all_data() which is written in such a way so as to handle duplicate .D files. But why? Because I was putting all the names into a dict. that's dumb. No .D file should be a duplicate because they will all have different filepaths, at least. And what's more, their metadata will intrinsically vary.

Actually, bugger that. Just assemble a list of Run_Dir objects then assemble the dataframe from that list.